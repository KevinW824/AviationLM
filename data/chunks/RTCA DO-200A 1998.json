{
  "source": "RTCA DO-200A 1998.md",
  "chunks": [
    "RTCA, Incorporated \n1140 Connecticut Avenue, N.W., Suite 1020 \nWashington, DC 20036-4001 USA \n\n## Standards For Processing Aeronautical Data\n\nPrepared by SC-181 \nÂ© 1998, RTCA, Inc. \n\nCopies of this document may be obtained from RTCA, Inc. \n\n1140 Connecticut Avenue, NW, Suite 1020 \nWashington, DC 20036-4001 USA \nTelephone: 202-833-9339 \nFacsimile: 202-833-9434 \nInternet: www.rtca.org Please call R \nTCA for price and ordering information. \n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## Foreword\n\nThis report was prepared by Special Committee 181 (SC-181) and approved by the RTCA Program Management Committee (PMC) on September 28, 1998.",
    "RTCA, Incorporated is a not-for-profit corporation formed to advance the art and science of aviation and aviation electronic systems for the benefit of the public. The organization functions as a Federal Advisory Committee and develops consensus based recommendations on contemporary aviation issues. RTCA's objectives include but are not limited to:",
    "- \ncoalescing aviation system user and provider technical requirements in a manner that helps \ngovernment and industry meet their mutual objectives and responsibilities; \n- \nanalyzing and recommending solutions to the system technical issues that aviation faces as it \ncontinues to pursue increased safety, system capacity and efficiency; \n- \ndeveloping consensus on the application of pertinent technology to fulfill user and provider \nrequirements, including development of",
    "requirements, including development of \nminimum operational performance standards for electronic \nsystems and equipment that support aviation; and \n- \nassisting in developing the appropriate technical material upon which positions for the International \nCivil Aviation Organization and the International Telecommunication Union and other appropriate \ninternational organizations can be based.",
    "international organizations can be based. \nThe organization's recommendations are often used as the basis for government and private sector decisions as well as the foundation for many Federal Aviation Administration Technical Standard Orders.",
    "Since RTCA is not an official agency of the United States Government, its recommendations may not be regarded as statements of official government policy unless so enunciated by the U.S. government organization or agency having statutory jurisdiction over any matters to which the recommendations relate. \n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## Executive Summary",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## Executive Summary\n\nThe RTCA Technical Management Committee established Special Committee 181 (SC-181) \nwith the following tenns of reference.",
    "- Special Committee 181 shall investigate the processes involved in the processing, \ncontrol and loading of \naeronautical databases, and produce guidance to ensure that: \na) \nThe integrity of \nthe civil aviation authority and the flight management \nsystem created source data is not degraded. \nb) \nThe databases are compatible with the type of \nequipment that will use them. \nc) \nThe databases are updated in ways that ensure that a) and b) remain current \nand valid.",
    "c) \nThe databases are updated in ways that ensure that a) and b) remain current \nand valid. \n- Special Committee 181 shall review current practices used in defining aeronautical \ndata and recommend any changes needed to provide improved operational \neffectiveness of \nairborne navigation systems that use stored databases. \n- Special Committee 181 shall co-ordinate its work with the European Organisation for \nCivil Aviation Equipment, Working Group 13 (EUROCAE WO 13). The results will",
    "Civil Aviation Equipment, Working Group 13 (EUROCAE WO 13). The results will \nbe the combined effort of \nthese two organisations, RTCA SC 181IEUROCAE WO 13. \nAfter reviewing the previous efforts of SC-lS7 and the documents that were published as a result of that effort, it was detennined that the basic infonnation contained in RTCA DO-200,",
    "\"Preparation, Verification, and Distribution of User-Selectable Navigation Data Bases\" and RTCA DO-201, \"User Recommendations for Aeronautical Infonnation Services\" was still applicable but needed updating to support new technology and the expanding scope of aeronautical data covered by this document. It was agreed that the guidelines covering the production of the aeronautical databases (RTCA DO-200) should be expanded to provide a more structured approach to the extremely important issues of",
    "should be expanded to provide a more structured approach to the extremely important issues of data quality and data integrity management. It was also agreed that aeronautical infonnation needed to support the efficient operation of computer-based systems had now become a requirement rather than a recommendation. The work of RTCA SC-181IEUROCAE WOl3 has resulted in two new documents:",
    "a) \nDO-200AlED-76, \"Standards for Processing Aeronautical Data\"; and, \nb) \nDO-20 \n1 \nAlED-77, \"Industry Requirements for Aeronautical Infonnation\" \nThese documents are submitted to the aviation community as a collection of disciplines necessary to provide assurance that the production of aeronautical databases meets the high integrity required for safe flight.",
    "This document provides a recommended minimum standard for the processing of aeronautical data. It is applicable to all phases of the aeronautical data process, from origination through acceptance and application by the end-user. It is intended to be used by organisations seeking approval of the methodes) they use to process or manipulate data. As a result, the document is structured in a manner, which will assist the organisation to:",
    "1) relate material obtained from the relevant regulatory authority to the requirements set \nforth herein; and \n2) determine if \nits processing methodes) meets the requirements. \nThe document is divided as follows: \nSection 1 -- is an introductory section which provides:",
    "- \ninformation on the purpose and scope of \nthe document; \n- \nan explanation of \nhow to use and apply the document; \n- \na list of \nbaseline documents used in the development of \nthe document; \n- \nan explanation of \nthe concept that the end-user of \nthe data has the ultimate \nresponsibility for defining requirements and ensuring that requirements are met; and, \n- \nan explanation of \nthe concepts of \ndata quality characteristics, required data quality,",
    "- \nan explanation of \nthe concepts of \ndata quality characteristics, required data quality, \nassuring quality through quality management, Aeronautical Data Chains and the \nfunctional links in those chains.",
    "functional links in those chains. \nSection 2 - defines the requirements. It establishes the users' responsibility for defining their data quality requirements. It provides requirements for aeronautical data processing and quality management, as it pertains to the aeronautical data process. Organisations intending to demonstrate compliance with this document will need to review this section to ensure that they meet all requirements relevant to their data processing activities.",
    "Section 3 -- describes a method, but not the only method, that can be used to demonstrate compliance with the requirements. States or approval authorities may determine that an application for approval using alternative methods of demonstrating compliance may also be acceptable.",
    "Appendix A - a glossary of \nterms and abbreviations used in the document; \nAppendix B - provides guidance on defining data quality requirements in support of \nthose \nrequirements expressed in Section 2; and \nAppendix C - provides guidance and further details on the methods available to demonstrate \ncompliance. \nThis page intentionally left blank:. \n\n## 1 Purpose And Scope 1.1 Introduction",
    "## 1 Purpose And Scope 1.1 Introduction\n\nThis document provides the minimum standards and guidance for the processing of aeronautical data that are used for navigation, flight planning, terrain awareness, flight simulators and for other applications.",
    "Such data would be passed on to the user as a database. The standard provides requirements that should be used to develop, assess change, and support implementation of data processing quality assurance and data quality management. When applied, the standard will provide the user with assurance of the level of quality that can be associated with the processed data, e.g. aeronautical database. \n\n## 1.2 How To Use This Document",
    "## 1.2 How To Use This Document\n\nThis document represents a consensus that has been reached within the aviation community. It has been written so that it may be applied by the regulatory authorities as an acceptable means of ensuring that aeronautical data maintains the required data quality and supports its intended application. It does not, in itself, have any authority over organisations responsible for processing aeronautical data.",
    "This document is intended to address the specific issues of the aeronautical data process. It assumes that those organisations have in place an acceptable quality management system and does not attempt to specify requirements other than those associated with the aeronautical data process.",
    "This document uses the term \"shall\" to identify requirements within this standard, which can be traced to particular aspects of the aeronautical data process. The term \"should\" is used where a procedure is recommended as an improvement to the aeronautical data process or to support demonstration of compliance, over and above the minimum requii'ements specified in this standard.",
    "Section 1 is informative, and defines the basic concepts associated with the aeronautical data process, including that of suppliers, users, and aeronautical data chains. Section 1 also describes some of the unique aspects of aeronautical data chains and examples are given as they apply to navigation and terrain data. This information is not intended to limit the potential application of this standard to other types of aeronautical data.",
    "Section 2 contains the requirements for the aeronautical data process. In support of this section, Appendix B provides guidance on defining the data quality requirements. Appendix C provides guidance for demonstrating compliance with the requirements of Section 2 of this standard. \n\nSection 3 specifies the objectives, procedures and reports associated with the audit of the aeronautical data process, in demonstrating compliance with Section 2 of this standard. \n\n## 1.3 Scope",
    "This document provides a minimum standard for all phases of the data process applicable to the processing of aeronautical data, including quality assurance and quality management. The standard will provide guidance to assess compliance and determination of the levels of process assurance. This standard supports the development and application of aeronautical databases, where an aeronautical database is a collection of data that is organized and arranged for ease of electronic storage and",
    "database is a collection of data that is organized and arranged for ease of electronic storage and retrieval in a system that supports airborne or ground based aeronautical applications. It is a complementary standard to those for data and applications listed in Section 1.3.2.",
    "## 1.3.1 Definition Of Terms\n\nThe definitions of terms used in this document are provided in a glossary in Appendix A.",
    "Several terms have been given specific and more restricted meanings than may be understood from general use, and full appreciation of the intended differentiation between terms that are often used as synonyms in nontechnical publications will be helpful to the reader. Accordingly, the definitions of accuracy, precision, resolution, integrity, quality, validation and verification are amplified in Appendix B, where their interrelationships are discussed. \n\n## 1.3.2 Reference Documents",
    "1. ICAO Annex 4, International Standards and Recommended Practices -\nAeronautical Charts \n2. ICAO Annex 11, International Standards and Recommended Practices -Air \nTraffic Services \n3. ICAO Annex 14, International Standards and Recommended Practices -\nAerodromes and Heliports \n4. ICAO Annex 15, International Standards and Recommended Practices -\nAeronautical Information \n5. RTCA DO-201A1EUROCAE ED-77, Industry Requirementsfor Aeronautical \nInformation",
    "5. RTCA DO-201A1EUROCAE ED-77, Industry Requirementsfor Aeronautical \nInformation \n6. RTCA DO-236IEUROCAE ED-75, Minimum Aviation System Performance \nStandards: Required Navigation Performance for Area Navigation \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "7. ICAO Doc 8126, Aeronautical Information Services Manual AN/872 \n8. ICAO Doc 9613, Manual on Required Navigation Performance AN/937 \n9. AEEC, ARINC *Specification* 424, Navigation System Data Base \n10. ICAO Doc 9674, *World Geodetic System* 1984, (WGS-84) AN/946 \n11. RTCA DO-178BIEUROCAE ED-12B, Software Considerations in Airborne \nSystems and Equipment Certification \n\n## 1.4 Application Of Standard",
    "## 1.4 Application Of Standard\n\nThe ultimate responsibility of ensuring that data meets the quality for its intended application rests with the end-user of that data. To a large extent, this responsibility can be met by obtaining data from a supplier accredited against this standard by an appropriate organisation. This does not alter the supplier's responsibility for any functions performed on the data.",
    "This standard is intended to assist the originators, the users and the regulatory authorities in meeting their responsibilities. To provide the most flexibility in applying this standard, two different types of applications are foreseen:",
    "1. an organisation meets all of the applicable requirements of this document, \napplied to a particular set of data quality requirements. This type of approval \nis tailored to organisations that process a limited amount of data, always of \nthe same type and always to meet the same user requirements; or, \n2. an organisation meets all of \nthe applicable requirements of \nthis document for a \ngeneral class of data. The quality management procedures are sufficient to",
    "this document for a \ngeneral class of data. The quality management procedures are sufficient to \ndevelop a data process for a new set of data quality requirements, without \nfurther evaluation. This type of approval is tailored to organisations that \nprocess a large amount of data for a number of different users, with different \nuser requirements.",
    "## 1.5 Concepts 1.5.1 Data Quality\n\nThe quality of data is its ability to satisfy the requirements for its safe application in the end system. The quality of aeronautical data and the way that it is processed is characterised by:",
    "1. Accuracy; \n2. Resolution; \n3. Assurance Level; \n4. Traceability; \n5. Timeliness; \n6. Completeness; and, \n7. Format \nThe seven characteristics listed above are defined in Appendix B. The degree that a data element meets the user's requirements determines its fitness for use. \n\n## 1.5.2 Required Data Quality",
    "## 1.5.2 Required Data Quality\n\nAirspace users, air traffic service providers and national aviation authorities have developed guidelines on the levels of risk that are judged to be acceptable for different phases of flight. These are defined either on the basis of risk pertaining to a specific operation, such as a landing, or as a risk of failure per flight hour.",
    "From an analysis of the potential causes of failure, and the allowable risk, it is possible to derive the allowable contribution to failure of the individual components of the system. \n\nBased upon such a breakdown, the user of aeronautical data is able to determine both the accuracy and resolution required for each data element and the necessary level of assurance that the data have not been corrupted (assurance level).",
    "The timeliness requirements are determined by the need to ensure that the data is applicable to the application period and the lead times required to ensure that it can be used in the stated validity period. \n\nA baseline set of such requirements for aeronautical data are set out in R \nTCA DO-\n201AlEUROCAE ED-77. \n\n## 1.5.3 Assuring Quality 1.5.3.1 Quality Management",
    "The nature of the aeronautical data process combines detailed data, with a multilevel data environment and related processes and procedures. In this end-to-end environment, data is: originated at its source(s), assembled, processed and formatted to meet the requirements of its end application(s) (see Figurel-l). A \nQuality Management Process is that which provides the framework upon which the procedures for doing the job are developed, managed, controlled, assessed, and changed.",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## Traceability 1.5.3.2\n\nAn essential part of any Quality Management Process is the need to validate and verify data. Where it is found that data does not meet the stated quality requirements it is necessary to determine the sources of the error to allow corrective action to be taken. To achieve this, data should be traceable to the supplier and to the next user, and errors should be traceable to their root causes.",
    "Note: The requirement for traceability extends from its original publication \n      through to its application. The aim of \n                                              such traceability is to ensure that all \n      anomalies or errors detected in use can be traced back to their origin, and \n      the resolution of \n                         the anomalies promulgated to all others who might be \n      affected. \n\n## Aeronautical Data Chains 1.5.4 1.5.4.1 Overview",
    "An \"Aeronautical Data Chain\" is a conceptual representation of the path that a set, or element, of aeronautical data takes from its creation to its end use. With an aeronautical data chain, as in a physical chain, each link is connected to its adjacent links. The symbolic links that make up an aeronautical data chain, may be as broad as organisations or departments within organisations, or, as refined as individuals or specific equipment. These are described in the following sections.",
    "Many different aeronautical data chains may contribute to a collection of data that is used by an end-user. When reading the sections of this document that refer to chain \"links\" or \"participants\", envision the functions performed by the organisation, and how the organisation handles aeronautical data to determine applicability to a particular situation.",
    "An aeronautical data chain is a series of interrelated links wherein each link provides a function that facilitates the origination, transmission and use of aeronautical data for a specific purpose. There are typically five major types of links in a chain and a chain can be of varying length as a link type can occur more than once. The functional links are; Origination, Transmission, Preparation, Application Integration, and End-Use of aeronautical data. A chain should be viewed as a circular",
    "Application Integration, and End-Use of aeronautical data. A chain should be viewed as a circular flow of information whereby the end use of aeronautical data determines what aeronautical data should be originated.",
    "Each of the functional links in a chain may be performed by a single organisation, or distributed among various separate organisations. For example, a state could originate, prepare, and integrate aeronautical information for a specific application prior to end use. Conversely, two examples of distributed aeronautical data chains are:",
    "1. an approach procedure may be originated by a State and issued into the public \ndomain. Another organisation may process ( \ncompile) the approach \ninformation, translate the information into coding (e.g. ARINC 424) and \ntransmit the result to a Flight Management Computer (FMC) application \nprovider. The Flight Management Computer (FMC) application provider, in \nturn, processes the data into a proprietary format that allows the target FMC",
    "turn, processes the data into a proprietary format that allows the target FMC \napplication to access the data. The resultant data is then integrated. \ninto the \ntarget FMC application; or, \n2. terrain data may be originated by a State and issued into the public domain. \nAnother organisation may process (compile) the terrain data, translate, format, \nand transmit the result to the terrain application provider. The application",
    "and transmit the result to the terrain application provider. The application \nprovider, in turn, processes the data into a proprietary format that allows the \ntarget application to access the data. The resultant data is then integrated into \nthe target application. \nTwo examples of aeronautical data chains, from origination of data through to the application of data by end-users are shown in Fiz:ures 1-1 and l.:.2.. The types of organisations included in the flow are:",
    "1. State Aeronautical Information Services or Terrain Data Agencies; \n2. Data Service Providers; \n3. Application Providers; and, \n4. End-users.",
    "2. Data Service Providers; \n3. Application Providers; and, \n4. End-users. \nEach of the boxes shown in Figures I-I and 1-2 can be associated with one of the organisations listed above. Within each box (organisation), an aeronautical data chain can have many links as each organisation may perform one or all of the functions that comprise chain links. The arrows between boxes represent the transmission link although the transmission link can occur within a box or between processes.",
    "Each of the function links in an aeronautical data chain is described below. Each of the descriptions includes the logical definition of the function, a historical perspective on who performs the described function, and some relevant existing regulation and/or guidance on requirements for performing the described function. \n\n## Aeronautical Data Origination 1.5.4.2",
    "## Aeronautical Data Origination 1.5.4.2\n\nOrigination is a functional link whereby values, names or other information are determined and assigned to required data elements for use in a subsequent functional link. For example, surveying to determine the elevation of the end of a runway, and calculating co-ordinates for a waypoint that is the intersection of two existing airways fall under the Aeronautical Data Origination functional link.",
    "Any and/or all participants in an aeronautical data chain may originate aeronautical data. Historically, most aeronautical data is originated by individual States. Other originators may supplement State originated data or originate data that is independent of the State. Examples of other chain participants that may originate aeronautical data include, but are not limited to, airlines, aircraft manufacturers, airport authorities, defence mapping agencies, and communication service providers.",
    "## Commentary On Navigation Data:",
    "The International Civil Aviation Organisation (ICAO) Standards and \nRecommended Practices (SARPs) for Aeronautical Information Services \n(AIS), published as Annex 15 to the Convention on International Civil \nAviation, requires each Contracting State to provide an AIS. \n                                                                    Each \nContracting State must take all necessary measures to ensure that the \naeronautical information/data it provides is adequate, of",
    "aeronautical information/data it provides is adequate, of \n                                                         required quality \n(accuracy, resolution and integrity) and provided in a timely manner for \nthe entire territory that the State is responsible for. It is incumbent upon \nthe national aviation authority in each State to arrange for the timely",
    "proviSion of \n            required aeronautical information to the AIS by each of \n                                                                      the",
    "State services associated with aircraft operations. The order of \n                                                                  accuracy \nfor aeronautical data is specified in Annex 11 - Air Traffic Services and \nAnnex 14, Volume I - Aerodromes and Volume II - Heliports. The \nspecifications for publication and charting resolution is specified in Annex \n15 and \n       Annex 4 - Aeronautical Charts,.",
    "In accordance with Article 38 of \n                                 the Convention, Contracting States are \nrequired to notify ICAO of any differences between their national \nregulations and \n               practices and the International Standards contained in the \nAnnexes, including Annex 15. Those differences are then published as \nSupplements to the Annexes. In addition, States are required to provide a",
    "list of \n        significant differences to related SARPs in a form that would enable \nthe user to differentiate readily between the requirements of \n                                                                                  the State and \nthe related ICA 0 provisions.",
    "Each State publishes permanent aeronautical information in an \nAeronautical Information Publication (AlP). \n                                        This is conventionally a \npaper document, containing text, tables and charts, a transition to the \nprovision of electronic aeronautical information by States is planned \nPermanent changes to the AlP are published as AlP Amendments. \nTemporary changes of long duration (three months or longer) and",
    "Temporary changes of long duration (three months or longer) and \ninformation of short duration that contains extensive text/graphics are \npublished as AlP Supplements. Information of \n                                         a temporary nature and \nshort duration is provided in the form of \n                                    Notice to Airman (NOTAM). \nInformation that does not qualifY for inclusion in the AlP, or in a NOTAM, \nis published as Aeronautical Information Circular (AIC).",
    "AlP Amendments and AlP Supplements that contain operationally \nsignificant information \n                      are published in \n                                         accordance \n                                                     with \n                                                          the \ninternationally accepted \n                        Aeronautical Information Regulation and \nControl (AlRAC) system. This system is based on the internationally",
    "Control (AlRAC) system. This system is based on the internationally \nagreed series of common effective dates at intervals of 28 days. The \ninformation must be distributed by the AIS at least 42 days in advance of \nthe effective date with the objective to reach the recipient at least 28 days \nin advance of \n           the effective date.",
    "Commentary on terrain data:",
    "No ICAO recommendations have been published for the collection, \nprocessing, publication and distribution of \n                                      terrain data. Therefore, it is \nincumbent upon the responsible agencies to ensure that the required \nterrain information originated by a number of \n                                         different data providers is \ncollected, processed, published and distributed to all interested aviation \nusers according to their requirements.",
    "Terrain data is not subject to the ICAO AlRAC revision cycle. Terrain \ndata changes may be triggered by better surveys, higher resolution data, \nadditional data availability and detected errors. \n\n## 1.5.4.3 Aeronautical Data Transmission",
    "Transmission is a functional link whereby data is moved from one physical location to another. This is a link that joins other processes and/or organisations and typically occurs many times in a data chain. For example~ State generated data being issued into the public domain, either on paper or electronically, electronic information being moved from one computer to another, and telephone \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\ncalls to relate information from one individual to another all fall under the Aeronautical Data Transmission functionallinlc There are many types of electronic transmission, such as copying files onto computer diskettes, modem communication, electronic mail and file transfer over the Internet. The primary issues associated with transmitting data are detecting errors and ensuring the data configuration management requirements are satisfied.",
    "Another consideration is the security of the transmission: e.g., protecting the data from modification by an external entity, or minimising the potential for accepting invalid data. Transmission is a function performed by all chain participants. Electronic transmission protocols typically involve some type of error checking to ensure the integrity of the transmission. \n\n## Aeronautical Data Preparation 1.5.4.4",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nPreparation is a functional link whereby a variety of aeronautical data elements are analysed, translated, compiled, and/or formatted to produce data configured for use in a subsequent functional link. The data may be received from one or more chain participants and may be in different configurations and formats. In the following examples, all activities fall under the Aeronautical Data Preparation functional link:",
    "1) processing information for an AlP amendment, entering AlP information into \na database, translating a chart or textual depiction of an approach procedure \ninto ARINC 424 coding, converting an electronic text file into a binary \nformat, and reformatting compiled data into a product specific format; and, \n2) acquiring charts or digital terrain elevation files, scanning and digiti \nsing the \nchart, entering terrain elevation in a database, analysing consistency of terrain",
    "sing the \nchart, entering terrain elevation in a database, analysing consistency of terrain \ncontours, converting to a reference co-ordinate system, compiling with \nprevious values for the same area, formatting compiled data into a product \nspecific format. \nAny participant in an aeronautical data chain can prepare aeronautical data.",
    "Typically, this is done by data originators, data service providers and application integrators. States issue volumes of information at a single time (such as AlP",
    "amendments). The information contained in the AlP is configured and formatted prior to its release. Data service providers combine existing data with data they have originated for the configuration and format requirements of target applications and/or required intermediate steps. Prior to use in a target application, aeronautical data may be prepared by multiple organisations.",
    "## 1.5.4.5 Aeronautical Data Application Integration\n\nApplication integration is a functional link in the process whereby data, in an application specific configuration and format, is made available to the target application. Two examples of the Aeronautical Data Application Integration functional link are loading information from a media storage device, such as a floppy disk, into the system's memory and filing a chart in a manual, for use inflight.",
    "Aeronautical information is usually integrated into an application by the specific application provider or the end-user. \n\n## 1.5.4.6 End-Use Of Aeronautical Data",
    "End-use is a functional link for accessing and acting upon the output of an application. For example, recalling a list of arrival transitions on an FMS, then selecting and flying the appropriate one; or selecting a route in a flight planning system, then receiving and flying the appropriate path both fall under the end-use of aeronautical data. As an additional example, having an alert in the cockpit, due to a potential conflict with terrain, also falls under the end-use of aeronautical terrain",
    "due to a potential conflict with terrain, also falls under the end-use of aeronautical terrain data. Aeronautical data end-users are typically aircraft operators, airline planning departments, air traffic service providers, flight simulation providers, airframe manufacturers, systems integrators, and regulatory authorities.",
    "## 1.5.5 A General Aeronautical Data Processing Model 1.5.5.1 Overview\n\nOf the Aeronautical Data Chain functional links described in Section 1.5.4 above \n(including sub-paragraphs 1.5.4.2 through 1.5.4.6), only the requirements for Aeronautical Data Preparation and Aeronautical Data Transmission are addressed in this document, see Section 2. Requirements for the other three functional links \n(origination, application integration, and end-use) are outside the scope of this document.",
    "Within the Aeronautical Data Preparation functional link there are four phases: \n\n1. Assemble \n2. Translate \n3. Select \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n4. Format \nEach participant in an Aeronautical Data Chain who processes data defines interfaces (requirements) with prior and subsequent chain participants. Each organisation therefore performs the Aeronautical Data Transmission function. \n\nWithin the Aeronautical Data Transmission functional link there are two phases:",
    "1. Receive \n2. Distribute \nThe applicability of this document to an Aeronautical Data Chain is illustrated in Figure 1-3. The figure also depicts the phases associated with the Aeronautical Data Preparation and Aeronautical Data Transmission functional links. These phases are described below. Figure 1-4 depicts a general Aeronautical Data Processing Model and the data flows between the phases of the Aeronautical Data Preparation and Aeronautical Data Transmission functional links.",
    "## 1.5.5.2 Aeronautical Data Transmission: Receive Phase\n\nThe receive phase involves the reception, verification and validation of data.",
    "The receive phase involves the reception, verification and validation of data. \n\nVerification of received data involves checks that ensure the integrity of the transmitted data. Validation involves checks of the data for applicability to its identity or as appropriate for its application. If errors, omissions or inconsistencies are identified, they are reported to the data supplier for correction and tracked by the receiving organisation to ensure that the deficiency is corrected.",
    "## 1.5.5.3 Aeronautical Data Preparation: Assemble Phase\n\nThe assemble phase involves the collection and collation of data from various suppliers.",
    "The assemble phase may result in a database that will meet the requirements of the next link in the chain. In the early stages of an Aeronautical Data Chain, for example, within a national AIS organisation, this may involve assembling inputs from surveyors, procedure designers and other services responsible for originating aeronautical data. In the later stages, it may involve assembling inputs from different chain participants that have already performed an Aeronautical Data Preparation",
    "from different chain participants that have already performed an Aeronautical Data Preparation function and translating the data into a format that supports the next process' requirements.",
    "Checks are carried out to ensure that the assembled data meets the quality requirements. If errors, omissions or inconsistencies are identified in the assembled data, they are reported to the responsible data supplier for analysis and correction and are tracked by the assembling organisation to ensure that the deficiency is corrected, or recorded for potential notification to the next participant in the chain.",
    "The source, accuracy, resolution and reported integrity of each data element, together with details of any changes made to received data, need to be recorded to assist in any future audit activity. \n\n## 1.5.5.4 Aeronautical Data Preparation: Translate Phase\n\nThe translate phase involves changing how information is expressed. \n\nFor example, textual descriptions of procedures may be converted to ARINC 424 leg types using the ARINC 424 coding rules.",
    "Checks are carried out to ensure the integrity of the original data is maintained after translation. \n\nNote: The assemble and translate phases are typically combined \n\n## 1.5.5.5 Aeronautical Data Preparation: Select Phase",
    "## 1.5.5.5 Aeronautical Data Preparation: Select Phase\n\nThis phase involves selecting specific data elements from the collection of aeronautical data produced by the assemble phase. The output from the select phase is a subset of the original collection that is matched to the data quality requirements of the next functional link in an Aeronautical Data Chain.",
    "During the select phase, checks are made to ensure that the subset collection of data elements is consistent with the original collection and that no individual data elements that are needed for completeness have been omitted. A procedure will normally exist for identifying the source of any deficiencies that are found and for \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\ntaking corrective action. Such corrective action may include co-ordination with the prior and/or subsequent chain participant, and may require additional iterations through the receive and assemble phases.",
    "## Aeronautical Data Preparation: Format Phase 1.5.5.6\n\nThe format phase involves converting the selected data sub-set into a format that is acceptable to the next functional link in the chain. This may take the form of the ARINC 424 standard format for the transfer of data for navigation, flight planning, simulator use; or a proprietary format for loading in a target system; or another agreed format. \n\nChecks are made to ensure that the data elements are compatible with the format selected.",
    "Checks are made to ensure that the data elements are compatible with the format selected. \n\nThe source of every error is identified in order that appropriate corrective action can be taken. \n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nAn integrity protection scheme that meets the minimum requirements for the data, such as the Cyclic Redundancy Check (CRC), is employed to protect the user from undetected errors once verification and validation have been successfully completed.",
    "The choice of the error detection scheme depends upon the requirements of the client as well as the risk of corruption posed by the storage and transfer. \n\n## 1.5.5.7 Aeronautical Data Transmission: Distribute Phase",
    "The distribute phase completes the processing data model and forms part of the transmission link in an Aeronautical Data Chain. This phase involves the delivery of the formatted data sub-set to users. Examples of delivery media are magnetic or optical media, solid state devices, or direct computer-to-computer links. These transfer methods allow automatic verification checks to be made using the integrity check values that resulted from the format phase. Where the distribute phase involves a",
    "integrity check values that resulted from the format phase. Where the distribute phase involves a number of discrete transfers, such verification checks need only be performed at the final transfer to ensure that no data loss or degradation has occurred. Additional protection may be provided within the specific distribution applications for part or all of the distribute phase.",
    "During the distribution process, checks are carried out to ensure that the distributed data meets the user criteria and that there are no media errors. If errors or omissions are identified, these are reported to the appropriate participant in the processing phase and procedures are followed to ensure that the deficiencies are corrected and recorded for potential notification to the end-users of the data. \n\n## 2 Requirements 2.1 Introduction",
    "As stated in Section 1 the nature of the data process leads to the necessity to implement techniques and procedures throughout the entire process to ensure the aeronautical data meets quality requirements. Such techniques and procedures are called a \"Quality Management\" process. The following section addresses these data quality, process, and quality management requirements. If any participant's process claims to meet these requirements, it is necessary to demonstrate compliance (refer to",
    "process claims to meet these requirements, it is necessary to demonstrate compliance (refer to Section 3) with these requirements.",
    "When the achievement of the data quality depends upon the quality of data obtained from a previous participant, then either the data accepted from the previous participant must be validated to the required level, or an assurance of data quality must be sought from that previous participant. For the majority of aeronautical data there is no benchmark against which the quality of data accepted from a previous link can be validated. The need to obtain assurance of the data quality will therefore",
    "a previous link can be validated. The need to obtain assurance of the data quality will therefore normally flow back through the system until it reaches the originator of each data element. Consequently, reliance must be placed upon the use of appropriate procedures in every stage of the process.",
    "## 2.2 Compliance Plan\n\nA compliance plan shall be prepared to document how requirements for processing aeronautical data will be accomplished. The plan shall address all aspects of the aeronautical data process carried out by the organisation choosing to comply with this standard. It shall identify:",
    "1. a definition of \ndata quality requirements; \n2. a definition of \naeronautical data processing requirements; \n3. a definition of \nquality management requirements; \n4. the identification of those responsible for compliance with the requirements; \nand, \n5. declaration of \nstandards that are used. \n\n## 2.3 Defining Data Quality Requirements 2.3.1 Overview",
    "## 2.3 Defining Data Quality Requirements 2.3.1 Overview\n\nAll participants in an Aeronautical Data Chain must ensure that data quality characteristics are correctly established for the data's intended usage, and that these data quality requirements are clearly documented. \n\n## 2.3.2 Data Quality Characteristics\n\nThe data shall have the agreed data quality, characterised by:",
    "1. the accuracy of \nthe data; \n2. the resolution of \nthe data; \n3. the confidence that the data IS not corrupted while stored or m transit \n(assurance level); \n4. the ability to determine the origin of \nthe data (traceability); \n5. the level of \nconfidence that the data is applicable to the period of intended use \n(timeliness); \n6. all of \nthe data needed to support the function is provided (completeness); and, \n7. the format of \nthe data meets the user requirements. \n\n## 2.3.3 User",
    "## 2.3.3 User\n\nThe user of aeronautical data shall: \n\n1. determine data quality requirements, See Appendix B; \n2. base the data quality of any particular data element upon the most restrictive \nrequirement for its application; \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "3. assure the quality requirements are attained. (This duty may be discharged by \nthe use of data from a data supplier, accredited against this standard by an \nappropriate organisation); \n4. determine the nature of \naction to be taken in the event of \ndiscovery of \nan error \nor inconsistency in the data; and, \n5. be responsible for establishing their requirement for being notified of data \nalteration. \n\n## 2.3.4 Supplierlprocessor",
    "## 2.3.4 Supplierlprocessor\n\nThe following requirements apply to a data supplier/processor:",
    "1. The supplier/processor shall provide data that meets the agreed user \nrequirements. \n2. The supplier/processor shall have a system for handling problems reported \nduring data processing, and those reported by the user after delivery of the \ndata. \n3. All problems reported with the data shall be analysed and any errors or \nanomalies, resolved and documented. \n4. All errors or anomalies detected in the data shall be resolved prior to delivery.",
    "4. All errors or anomalies detected in the data shall be resolved prior to delivery. \n5. Information concerning any errors or anomalies found in the data after it has \nbeen delivered, shall be made available to all affected users. \n6. The means by which errors or anomalies are resolved shall be reported to all \naffected users.",
    "## 2.3.5 Documentation Requirements (User/Supplier)\n\nThe following requirements apply to documentation: \n\n1. The data quality requirements shall be documented. \n2. The delivery format requirements shall be documented. \n3. Documentation shall be maintained that identifies all the suppliers of data, \nused by the organisation, and the approval status of each. For navigation data, \nan approved supplier is either a State or a RTCA DO-200AlEUROCAE ED-\n76-compliant supplier.",
    "## 2.4 Aeronautical Data Processing Requirements 2.4.1 Data Processing Procedure Requirements\n\nThe Data Processing Procedures shall define:",
    "1. \nthe means used to confirm that the data has been received without \ncorruption; \n2. \nthe means by which data is assembled; \n3. \nthe means used to ensure that stored data is protected from corruption; \n4. \nthe method of \norigination for all data that is originated locally; \n5. \nthe means used to confirm that data that is originated locally has not been \ncorrupted prior to being stored; \n6. \nthe means by which validation of any data element is to be performed. This \nshall include: \na)",
    "6. \nthe means by which validation of any data element is to be performed. This \nshall include: \na) \nwhen the supplier is not approved, the means by which an \nappropriate validation can be performed; \nb) \nwhen multiple suppliers are available for a data element, the means \nby which differences between them are determined and resolved; \nand, \nc) \nwhen separate data elements have a defined relationship, the means \nby which this relationship is confirmed and any anomalies are \nresolved; \n7.",
    "by which this relationship is confirmed and any anomalies are \nresolved; \n7. \nthe action to be taken when data fails a verification or validation check; \n8. \nthe method to be used to evaluate degradation of accuracy when the \nresolution of a data element is reduced, or the data is translated into a \ndifferent co-ordinate system or unit of \nmeasurement; \n9. \nthe requisite skills and competencies necessary to perform each procedure; \n10. \nthe tools required for the procedure; \n11.",
    "10. \nthe tools required for the procedure; \n11. \nthe method to be used to verify received data; \n12. \nthe method by which data quality is preserved; \n13. \nthe method by which the user is assured that, whenever the resolution of a \ndata element is changed, or the data value is translated, the accuracy and \nresolution of \nthe new value meets the data quality requirements; and, \n14. \nthe method to be used to provide the user with the ability to verify that the",
    "14. \nthe method to be used to provide the user with the ability to verify that the \ndata received by the user has not been corrupted.",
    "## 2.4.2 Data Alteration Communication Requirement",
    "A user shall not alter the data from any supplier without informing the data originator of the change and endeavouring to receive concurrence in a timely manner. Altered data shall not be transmitted to the user if the originator rejects the alteration. Records shall be kept of all alterations and shall be made available to all subsequent users on their request. This requirement only applies to the alteration of the data, and does not apply to assembling, translating, selecting, or formatting",
    "the alteration of the data, and does not apply to assembling, translating, selecting, or formatting the data. For example, defining a path other than that associated with the procedure, deleting a fix that is published as part of the procedure, or changing the name of a fix that was named by the data originator are all considered to be data alterations.",
    "## 2.4.3 Data Configuration Management\n\nThe objectives of data configuration management are to:",
    "1. ensure that data configuration controls have been implemented to provide \nassurance that data values in delivered data products are applicable to the \ndeclared period of \nvalidity; \n2. support the requirement for traceability of \neach data element to its source; \n3. reduce the vulnerability of the data processing activities to loss or corruption \nof \nstored data, regardless of \nthe media or system used to store the data; and,",
    "of \nstored data, regardless of \nthe media or system used to store the data; and, \n4. reduce the vulnerability of the data processing activities to unintentional \ndeviations from requirements of one user introduced by meeting the \nrequirements of \nanother user.",
    "## 2.4.3.1 Data Configuration Management Plan Requirements\n\nThe data configuration requirement activities shall be defined and documented in a Data Configuration Management Plan. The plan shall identify all data to be placed under configuration management. It shall include: \n\n1. all delivered data products; and, \n2. all data that are identified in the planning process as required to be stored to \nensure that the production process can recover from data loss or data \ncorruption.",
    "## 2.4.3.2 Data Configuration Management Requirements\n\nThe following requirements apply to the data placed under configuration management. Each distinct version of a data element shall be assigned a unique identification. The data element identification shall be contained within the data element, as well as being used as a physical label attached to any portable storage medium used to hold the data elements.",
    "The configuration management procedures shall ensure that a data element cannot be changed without changing the data element identification. \n\nRecords shall be maintained that identify the data content of all data elements in order to support traceability. \n\nThese records shall be sufficient to allow the following to be established: \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---",
    "1. that a data value has not been separated from its correct label; \n2. the start and end dates of \nthe period of \nvalidity of \nthe data element; \n3. the date of \nproduction of \nthe data element; \n4. the supplier of \neach data value contained within the data element; and, \n5. the procedures used to produce the data element. \nA copy of each data element shall be retained for a period determined by the Configuration Management Plan.",
    "The method of storage, and the numbers of copies held, shall be such that: \n\n1. the integrity of \neach data element can be assured for the entire period that it is \nto be retained; and \n2. due attention is given to protection against physical damage and degradation. \n\n## 2.4.4 Skills And Competencies\n\nThe objectives of skills management are to:",
    "## 2.4.4 Skills And Competencies\n\nThe objectives of skills management are to: \n\n1. \nestablish the skills required for each step of \nthe process; and, \n2. \nensure that personnel assigned to perform data processing have the necessary \nskills, competencies, and knowledge of \nthe procedures. \n\n## Skills And Competencies System Requirements 2.4.4.1",
    "## Skills And Competencies System Requirements 2.4.4.1\n\nProcedures shall be established that defme the means that personnel may acquire or maintain the skills and competencies required for the applicable procedure. \n\nSkills and competencies can be obtained from a variety of means, such as basic education, formal academic training, vocational courses, on-the-job training, or supervised accumulation of experience.",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nAppropriate records of skills and competencies shall be maintained so that the qualifications of personnel assigned to perform specific procedures can be confirmed. \n\nShort-falls in skills and competencies shall be identified and corrective actions shall be taken. \n\n## 2.4.5 Aeronautical Data Tool Qualification",
    "## 2.4.5 Aeronautical Data Tool Qualification\n\nTools (e.g. software) can be used to automate the activities associated with an aeronautical data process. Tool qualification is the process by which assurance is achieved that tools employed will neither introduce errors into the data nor degrade integrity or traceability. Tool qualification should be done within the context of the tool's intended use. \n\nCommentary:",
    "The scope of \n             the tool qualification will depend upon the data quality requirements \nand the role of the tool in the aeronautical data process. \n                                                                A tool used for \nproduction/modification of data will typically require a more rigorous \nqualification process than a tool used \n                                      for verification of \n                                                         data.",
    "data. \n                                                                This is necessary \nto ensure that the operation of \n                              the production/modification tool will not introduce \nerrors.",
    "The objectives of \n                 tool qualification are: \n\n1. to demonstrate that the tool complies with the user's intended requirements; \nand, \n2. to ensure that the tool provides equivalence to any activities that it automates, \nand that the tool qualification is commensurate with the tool's intended use, or \nthe data production process. \n\n## 2.4.5.1 Applicability Of Tool Qualification",
    "## 2.4.5.1 Applicability Of Tool Qualification\n\nQualification of the tool is needed when data processes are eliminated, reduced or automated by the use of a tool without the output being verified. The following requirements apply equally to tools obtained \"off the shelf' Of developed by the data processor either as a stand-alone product or as a module within an existing product.",
    "1. Each proposal for a new tool, or for a modification of \nan existing tool, shall be \nreviewed to determine whether the tool is required to undergo qualification. \n2. Where a decision is made that qualification is not required, justification for \nthat decision shall be documented. \n\n## 2.4.5.2 Tool Qualification Plan\n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nThe tool qualification plan shall describe the tool qualification process and shall identify:",
    "1. the tool requirements; \n2. the tool qualification procedures; \n3. the tool configuration management procedures; \n4. the tool qualification documentation requirements; \n5. the applicable quality management procedures; and, \n6. those responsible for the qualification process, including the authority vested \nin them. \n\n## Tool Requirements 2.4.5.3\n\nThe Tool Requirements for the tool shall be defined and shall include:",
    "The Tool Requirements for the tool shall be defined and shall include: \n\nI. the functionality of \nthe tool; \n2. the performance of \nthe tool; \n3. a description of \nthe tool's operational environment; and, \n4. user information, such as installation guides and user manuals. \n\n## Tool Qualification Procedures 2.4.5.4\n\nThe tool qualification procedures shall specify:",
    "## Tool Qualification Procedures 2.4.5.4\n\nThe tool qualification procedures shall specify: \n\n1. The means by which it is ensured that the data output from the tool has the \nrequired data quality. This could be achieved by review, analysis or the \nexecution of \na comprehensive set of \ntest procedures. \n2. The means by which it is ensured that the tool satisfies the Tool \nRequirements. \n\n## Tool Configuration Management 2.4.5.5\n\nThe tool configuration management process shall provide:",
    "1. a unique identification for each distinct version of \na tool; \n2. the means for convenient availability/visibility of \nthe tool version; \n3. the ability to consistently replicate or regenerate a particular version of the \ntool; \n4. a change control process which establishes recording, evaluation, resolution \nand approval of changes throughout the tool development and the tool's life; \nand, \n5. a secure environment for physical archiving, recovery and control for \nconfigured items.",
    "## Tool Qualification Documentation Requirements 2.4.5.6\n\nFor tools utilised in aeronautical data processes, documents and reports shall be maintained to show that the tool qualification activities have been completed satisfactorily. If modifications or changes are made to the tools, additional qualification activities and supporting documentation may be necessary. \n\n## Quality Management 2.5",
    "## Quality Management 2.5\n\nThe prerequisite to the quality management requirements is the adoption of a set of documented procedures that cover all aspects of aeronautical data processing. \n\nThese have been defined in the preceding sections. Supporting these procedures are quality management procedures that ensure that:",
    "1. \ndata accepted from a supplier meets the agreed data quality requirements; \n2. \nvalid data processing procedures are applied; \n3. \nprocedures are adhered to and there is no unauthorised deviation from the \nprocedures; and, \n4. \nreviews and controls are in place to ensure quality. \nThe means used to specify the quality management requirements is not intended to be prescriptive. Compliance can be demonstrated by any quality management structure that meets the requirements of this document.",
    "In the following sections, the phrase \"plans and procedures\" includes the following: \n\n1. \ncompliance plan; \n2. \ndata quality requirements; and, \n3. \ndata processing, including: \na) \nprocedures; \nb) \nconfiguration management; \nc) \nskills and competencies; and, \nd) \ntools. \n\n## 2.5.1 Quality Management (Qm) Procedure Requirements\n\nThe QM procedures shall:",
    "1. define the criteria used for the review of plans and procedures, including the \nmaximum interval between reviews; \n2. define the criteria used for the review of personnel skill records including the \nmaximum interval between reviews; \n3. define the criteria used for the review of qualified tools, including the \nmaximum interval between reviews; \n4. identify who will have the authority to approve plans and procedures;",
    "4. identify who will have the authority to approve plans and procedures; \n5. identify who will have the authority to certify that personnel have satisfied \nskill and competency requirements; and, \n6. identify who will have the authority to authorise (qualify) tools for use. \nNote: There is no requirement for all plans and procedures to be reviewed at the \nsame periodic rate.",
    "## 2.5.2 Quality Management Control\n\nAll plans and procedures, including changes, shall be reviewed and approved prior to their application as described in the QM procedures. This review shall include a review of the ability of data suppliers to supply the new data with the required data quality, if applicable. \n\nThe current version of the approved procedures is referred to as the authorised version of the procedures.",
    "If unauthorised deviations from the procedures are discovered, corrective action shall be taken. The corrective action may include changing the procedures and/or the skills competency requirements.",
    "All personnel who carry out any of the procedures shall be qualified to apply those procedures. The personnel shall have access to the authorised version of the procedures. If changes to the procedures are approved, the personnel shall be notified of the changes. Obsolete versions of documents shall not be used. \n\nAll tools, including updated versions of tools, shall be reviewed and approved prior to their application as described in the QM procedures.",
    "Records of procedures, personnel and tools shall be kept to allow identification of the procedures, personnel and tools employed in the production of each delivery of data to a client. \n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## 2.5.3 Ltevielv\n\nRecords of all reviews shall be maintained. The records shall: \n\n1. identify the date of \nthe review; \n2. identify who conducted the review; and, \n3. identify any non-conformities or deficiencies and how they are resolved.",
    "## 2.5.3.1 Event-Driven\n\nThe plans and procedures shall be reviewed when there is a proposal to supply new data, changes in the procedures (e.g. for improvements) and changes in any tools. Where such a review identifies that changes to the procedures are required, these shall be implemented prior to initial delivery of the new data. This review shall include an evaluation of the ability of data suppliers to supply the new data with the required data quality.",
    "The records of skill shall be reviewed for new personnel or personnel assigned new tasks. Personnel shall be authorised as having the necessary skills before participating in the data process. \n\nEach new or modified tool must undergo qualification as described in Section \n2.4.5. \n\nWhen a data error is detected, either internally or reported by users, action shall be taken to correct the procedures, skills, or tools to ensure that the error will not be repeated. \n\n## 2.5.3.2 Periodic",
    "## 2.5.3.2 Periodic\n\nAll plans and procedures that define the data processing and quality management requirements shall periodically be reviewed as defined in the QM procedures to ensure their continuing ability to support the data quality objectives.",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nThe records of the skill for personnel on the various data processing tasks shall periodically be reviewed as defined in the QM procedures. The review shall confirm that the personnel have the required skills identified in the data processing procedures. \n\nTools shall periodically be reviewed as defined in the QM procedures to confirm the continuing ability of the tool to meet the data quality requirements.",
    "If the responsibility of achieving data quality is partially discharged by receiving data from an accredited supplier, the accreditation of suppliers against this standard shall periodically be confirmed.",
    "All records of detected data errors, both those detected internally and those reported by users, that are attributed to the local processing and maintenance of data, shall be reviewed periodically, as defined in the QM procedures, to consider implications on the data processing procedures or QM procedures. If action is taken as a result of a review, the action shall be recorded.",
    "All periodic reviews shall include a review of all problems recorded during the use of the procedures, personnel, or tool and all recorded data errors attributed to the subject of the review. The impact of any deficiencies or limitations on the quality of the aeronautical data shall be assessed and corrective action shall be taken if necessary to ensure that data meets the data quality requirements. \n\n## 2.5.4 Quality Records",
    "## 2.5.4 Quality Records\n\nA quality record is a document that furnishes objective evidence demonstrating conformance to specific requirements and/or the effective operation of a quality management system. Quality records may be in the form of any type of media, such as hard copy or electronic media. \n\nQuality records are also used to identify if procedures need to be modified to correct deficiencies. \n\nWhere procedures require that records be kept:",
    "Where procedures require that records be kept: \n\n1. \nretention times of \nsuch records shall be established and recorded; \n2. \nrecords shall be legible and identifiable to the product involved; and, \n3. \nrecords shall be retrievable from reliable facilities that minimise loss and \nprovide a low probability of \ndeterioration. \n\n## 2.5.5 Management Reviews\n\nThe records described in Section 2.5.4 shall be reviewed by the level of management responsible for meeting the data quality requirements.",
    "Reviews shall: \n\n1. confirm that the documented plans and procedures associated with quality \nassurance have achieved the required levels of \ndata quality, and; \n2. evaluate the need for corrective and preventive actions. \nThe results of such reviews shall be recorded. \n\n## 3 Compliance 3.1 Demonstration Of Compliance",
    "## 3 Compliance 3.1 Demonstration Of Compliance\n\nAll organisations claiming compliance with the standards of RTCA DO-\n200AlEUROCAE ED-76 shall demonstrate such compliance to the applicable sections. Compliance is normally demonstrated by audit but other methods may be acceptable as determined by the supplier and the affected organisation (for example, the user of the supplied data or a regulatory authority). This section focuses on audit as the means of demonstrating compliance.",
    "An audit of compliance shall be a systematic examination against all of the requirements of this document. The audit may be conducted against another document that contains these requirements. Audits should not lead to an increase in the scope of quality functions solely to support the audit.",
    "The audit can be carried out by an external organisation (for example the user of the supplied data or a regulatory authority) or delegated to the data supplier as an internal function when authority to do so is conveyed by an appropriate external organisation. The review shall be carried out by personnel independent of those having direct responsibility for carrying out the procedures.",
    "It is important to note that the audit does not result in a transfer of responsibility to achieve quality from the processing function to the auditing function. The auditor is responsible only for determining conformity with the processes and procedures that govern the Aeronautical Data Chain tasks being performed. The supplier is responsible for compliance with requirements of the standard which may be this document or another approved standard consistent with this document.",
    "## 3.2 Audit Objectives\n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nThe audit shall confirm that:",
    "1. authorised versions of all plans, and procedures associated with data quality \nassurance, the processing of aeronautical data, and quality management \nrequirements (as defined in Section 2) are available; \n2. controls exist to ensure that the plans, and procedures associated with data \nquality assurance, the processing of \naeronautical data, and quality management \nrequirements are followed; and, \n3. the quality system meets all requirements as defined in Section 2, and that any",
    "3. the quality system meets all requirements as defined in Section 2, and that any \ncompliance deviations have been documented and tracked. \n4. procedures exist for the management of changes to the data processing \nprocedures, and that they provide assurance that revised data processing \nprocedures are capable of \nmeeting the stated quality requirements.",
    "## Audit Procedures 3.3\n\nThe auditing procedures shall:",
    "1. be documented and maintained by the auditor; and, \n2. define the criteria for determining the need for an audit to take place. This \nincludes the number and types of changes to procedures that shall require an \naudit to be conducted and the frequency that periodic audits are to be \nconducted.",
    "audit to be conducted and the frequency that periodic audits are to be \nconducted. \nThe procedures shall ensure that all aspects of the data processing system and the quality management system are subject to audit on the basis of elapsed time since previous audit and upon the occurrence of a major change. The audit of adherence to the procedures may be executed in a progressive and incremental manner.",
    "Where the procedures allow the audit to be performed by incremental audit of different parts of the data processing or quality management system, the justification for such an approach shall be documented, and regularly reviewed to ensure that the justification remains valid. \n\nNote: It is recommended that the maximum time between audits whether total or \nincremental be not more than one year. \n\n## Audit Reports 3.4",
    "All audit observations shall be documented. The auditor shall review all observations to determine which observations are to be reported as nonconformities. The auditor shall ensure that non-conformities are documented in a clear concise manner, and that they are supported by evidence. Non-conformities should be identified in terms of the specific requirements of this document that have not been met. A copy of the audit report shall be delivered to the organisation being audited.",
    "Non-conformities shall be categorised as follows:",
    "1. Major Non-Conformity - The process does not comply with the requirements \nof this standard and immediate corrective/preventive action is required. A \nmajor non-conformity typically results when a significant quality management \nsystem requirement has either not been defined, documented, or implemented. \nA major non-conformity indicates a systemic failure of the quality \nmanagement system. \n2. Minor Non-Conformity - The process continues to comply with the \nrequirements of",
    "2. Minor Non-Conformity - The process continues to comply with the \nrequirements of \nthis standard but requires corrective action within a specified \ntime period. \nA minor non-conformity typically results from objective \nevidence that a portion of the quality management system is not consistently \nimplemented, or needs improvement in order to more completely fulfil the \nrequirements. \n3. Observation - The process does not require corrective action. An observation \nis a statement of",
    "3. Observation - The process does not require corrective action. An observation \nis a statement of \nopinion by the auditor for consideration.",
    "## Membership Rtca Special Committee *1811* Eurocae Working Group 13 Navigation Standards\n\nNorthwest Airlines UK Civil Aviation Authority Co-Chairs Frank Alexander Geoffrey Burtenshaw Federal Aviation Administration \n\n## Secretary Bruce Decleene\n\nDelta Airlines Douglas Aircraft Company Texas Instruments, Inc. \n\nBoeing Commercial Airplane Co.",
    "SAIC-SCT Group Members and Advisors Robert Ainsworth Romel Aminmadani Mike Amundsen William J. Anacker Robert K. Anoll Ken Ashton John W. Bail Claude Baileau Roger Baker Pat Banks Clayton Barber Jean Baron John Barrer Carlo Bassani Jerry M. Battenhouse Michael Beamish Martin Beckmann August H. Beining Vincent L. Bencivenga Gerald E. Bendixen Chris Benich Steve Bergner Joel Berkoukchi Jack Bertron Hughes Bidel Robert W. Billings Richard J. Biro William A. Blake Ronald M. Bolton Phil Boughton",
    "Hughes Bidel Robert W. Billings Richard J. Biro William A. Blake Ronald M. Bolton Phil Boughton Carl F. Bowlen Jerry Bradley UK National Air Traffic Servo Narco Avionics, Inc.",
    "Air France Eldec Corporation US Airways Garmin International, Inc. \n\nDGAC/SPAe The MITRE Corporation Meridanana Airlines Air Line Pilots Association Pelorus Navigation Systems, Inc. \n\nTrimble Navigation Hughes Aircraft Company VLB Associates Rockwell Collins Honeywell, Inc.",
    "Trimble Navigation Hughes Aircraft Company VLB Associates Rockwell Collins Honeywell, Inc. \n\nCableair Sextant A \nvionique Federal Aviation Administration Sextant A \nvionique GARMIN International Rockwell-Collins Federal Aviation Administration National Oceanic Service Air Transport Association of America Federal Aviation Administration System Resources Corporation The MITRE Corporation NOS/ACC \nConsultant AlliedSignal Aerospace Co Inc United States Air Force Honeywell, Inc.",
    "UK - Civil Aviation Authority Federal Aviation Administration DGAC/STNA \nSikorsky Aircraft Trimble Naviagation Ltd Rannoch Corporation Delco Systems Ops Sextant A \nvionique Sextant A \nvionique Air Economics Group, Inc. \n\nAtlantic Coast Airlines Rockwell Collins, Inc. \n\nU. S. Navy Air Line Pilots Association Smiths Industries NIMA St. Louis STASYS Ltd. \n\nUniversal Avionics Systems Corp. \n\nF \nederal Aviation Administration EUROCONTROL \nTrimble Navigation Universal Avionics Systems Corp.",
    "Aerospatiale Aerospatiale International Air Transport Assn. \n\nAlliedSignal Aerospace Co Inc ARINC, Inc. \n\nSAIC \nGARMIN International, Inc. \n\nNational Geodetic Survey Rockwell-Collins Adsystech, Inc. \n\nFederal Aviation Administration U. S. Air Force. \n\nHoneywell, Inc.",
    "F \nederal Aviation Administration Federal Aviation Administration Federal Aviation Administration Canadian Marconi Company F \nederal Aviation Administration Honeywell Suzanne Bradley Charles Branch Joel Breazeale Frank 1. Brem Grover C. Brown Dave Burdon Ludmilla Burt Susan J.M. Cabler Philippe Caisso",
    "1. 1. Carson Gerry Carson Rick 1. Cassell Claude Castelbou Bruno Cazali Philippe Chaix George C. Chang Vincent Chirasello George A. Cobley Glenn Colby Kevin Comstock Michael R. Cramer Jack Crawford John Curtis Charles F. Cusack Evan R. Darby Jeremy Davidson Darrell W. Davis James M. Davis Hughes de Beco Gilles DeCevins Louis Desmarais Kelly Dillard John C. Dobyne Chip Dorman John Doughty David Doyle Gary Dwen Paul Ebert David W. Eckles Malcolm C. Emerick Jary Engels Jim Enias Robert Erikson Pat",
    "Gary Dwen Paul Ebert David W. Eckles Malcolm C. Emerick Jary Engels Jim Enias Robert Erikson Pat Fair Sohel Fares Robert Fischer Terry Flaishans Crown Communications, Inc.",
    "A \nvroTec, Inc. \n\nContinental Air Lines, Inc. \n\nAll Nippon Airways Co., Ltd. \n\nU. S. Navy Douglas Aircraft Company Airbus Industrie AlliedSignal Aerospace Co. Inc. \n\nSystem Resources Corp. \n\nBFGoodrich Avionics Systems Rosemont Aerospace Inc. \n\nHoneywell, Inc. \n\nRaytheon Systems Company AlliedSignal Aerospace Co Inc Mesaba Airlines Sterling Software ARINC, Inc. \n\nCanadian Marconi Company United Airlines, Inc. \n\nInternational Air Transport Assn.",
    "Canadian Marconi Company United Airlines, Inc. \n\nInternational Air Transport Assn. \n\nTransport Canada EUROCAE \nF \nederal Aviation Administration Rockwell Collins BFGoodrich Avionics Systems Air Line Pilots Association Honeywell, Inc, Honeywell, Inc Federal Aviation Administration United Parcel Service Honeywell, Inc.",
    "Jeppesen Co. Gmbh British Airways Federal Aviation Administration EUROCAE \nInnovative Solutions International Federal Aviation Administration Transport Canada Rockwell Collins AlliedSignal Aerospace Co. Inc. \n\nHughey & Phillips Mesaba Airlines Advanced Nav. & Position Corp.",
    "Trimble Navigation The MITRE Corporation Federal Aviation Administration Pat Fletcher Ken Foote George Fox Shunichi Furue Ian T. Gallimore Neil Gallon Hermann Ganz Robert Gaul Robert Geary Blake Getson John Ginn R. David Girts Rocklin R. Gmeiner David Goddard Kluus Goersch Tsuyoshi Goka Roger S. Goldberg Michael Gordon-Smith Tom Graff Tore R. Granaas Jim Gregory Francis Grimal Roy Grimes Donald Grimm Brett Gundlach Charles K. Guy Jim Haberstock Allan Hart Michael Hawthorne Robert Hilb John",
    "Grimm Brett Gundlach Charles K. Guy Jim Haberstock Allan Hart Michael Hawthorne Robert Hilb John Hillier Bodot Hohnberg Ian Hudson Alfred E. Hughes Geoff Hunt M. Stephen Huntley Tom Imrich Douglas Ingold Richard Jinkins Robert Johns Peter H. Johnson Peter Johnson Dale E. Johnson Rudolph Kalafus Elliott D. Kaplan Robert 1. Kelly",
    "Â©1998, RTCA, Inc.",
    "U. S. Air Force Transport Canada II Morrow, Inc.",
    "Federal Aviation Administration J \neppesen-Mentor ALP \nAlUS Airways National Aeronautics & Space Administration Northstar Technologies Illgen Simulation Technologies, Inc EUROCONTROL \nAir Line Pilots Association Federal Aviation Administration F \nederal Aviation Administration Jeppesen Sanderson A \nvidyne Corporation F \nederal Aviation Administration Atlantic Coast Airlines Jeppesen Sanderson DGAC/STNA \nSmiths Indu. Aero & Defense Sy Aerospatiale F",
    "Smiths Indu. Aero & Defense Sy Aerospatiale F \nederal Aviation Administration Litton Aero Products F \nederal Aviation Administration Seagull Technology, Inc.",
    "The MITRE Corporation F \nederal Aviation Administration Federal Aviation Administration NOAA \nF \nederal Aviation Administration RTCA, Inc. Federal Aviation Administration Boeing Commercial Airplane Group All Nippon Airways Co., Ltd. \n\nMayflower Communications Rockwell Collins NASA Ames Research Center ICAO \nAurcraft Electronics Association Litton Systems, Aero Products Div. \n\nNATS, Ltd. \n\nF \nederal Aviation Administration Northwest Airlines, Inc.",
    "Air Line Pilots Association Smiths Indu. Aero & Defense Sy Jeff King Alexander Korolov Waldemar R. Krolak Marvin A. Kumley Thomas 1. Laginj a John Laurin Simon Lawrence Victor Lebacqz Scott C. Lewis Robert W. Lilley C. M. Loghides Howard A. Long George Lyddane Michael Magrogan Chet Mason Simon Matthaws Leslie McCormick Sean McCourt Barry T. McDaniel Veronique Melet Pete Mellema Jean-Pierre Metivier Jeff Meyers Charles Michaels Natalie Miller Joseph A. Miller Satish C. Mohleji Jim Moon Carl",
    "Jeff Meyers Charles Michaels Natalie Miller Joseph A. Miller Satish C. Mohleji Jim Moon Carl Moore John R. Moore Robert L. Morton Harold Moses William M. Mosley David A. Nakamura Y",
    "oshinobu Nakanishi Peter Nicolaides Gary Owen Everett Palmer Aleksandar Pavlovic Terry L. Pearsall Richard Perrin Bernard Perry Ivan Petrenko William F. Petruzel Mike Pfleiderer William J. Phaneuf Bill Phebus AlliedSignal Aerospace Co Inc AvCom, Inc.",
    "Deering Sys. Design Consultant ARINC Incorporated NIMA \nAmerican Trans Air EUROCONTROL \nF \nederal Aviation Administration Austrian Airlines Base Southwest Airlines Company Delta Airlines, Inc. Boeing Commercial Airplane Company Raytheon Aircraft E-Systems Montek F \nederal Aviation Admininistration Interstate Electronics Corp. \n\nJeppesen Sanderson, Inc.",
    "Jeppesen Sanderson, Inc. \n\nCanadian Marconi Company Russell Systems Inmarsat F \nederal Aviation Administration Rockwell Collins National Aeronautics & Space Administration National Business Aviation Association Boeing Commercial Airplane Group Honeywell Inc Innovative Solutions Intern'l Rockwell-Collins Continental Air Lines, Inc. \n\nJeppesen Co. Gmbh Ohio University Universal Avionics Systems Corp, WA \nSoaring Society of AmericaiFIA \nBoeing Commercial Airplane Co.",
    "AlliedSignal Aerospace Co Inc Crown Communications, Inc Delta Airlines, Inc. Federal Aviation Administration Canadian Marconi Company Jeppesen Sanderson Aviso, Inc. \n\nExperimental Aircraft Association Defense Concept Associates, Inc.",
    "Jeppesen Sanderson Honeywell Inc Litton Rockwell Collins Gerard Philippe R. Andrew Pickens H. Robert Pilley Paul J. Prisaznuk Lynne E. Puetz Mary A. Randall Roland C. Rawlings Albert J. Rehmann Erich Reiterer Mike Rickman Tim V. Rider Michael Ripp Glyn K. Romrell F. Charles Rosario Alan Ross Rudolph M. Ruana William Ruhl William M. Russell Fintan R. Ryan Rosanne Ryburn Ellen L. Schaefer Herbert W. Schlickenmaier Gerald C. Schroeder Robert W. Schwab Lou Selk Ralph D. Sexton Dennis Shaver Samuel",
    "Schlickenmaier Gerald C. Schroeder Robert W. Schwab Lou Selk Ralph D. Sexton Dennis Shaver Samuel L. Shirck Ralf Sieprath Trent A. Skidmore Sam Slentz Bernald S. Smith George Sotolongo Christine Stahl Ken Staub Keith Stover Robert I. Stuckert John Studenny Tim Sukle Abdul M. Tahir Donald J. Taylor Tom S. Teetor Jim E. Terpstra Yannick Thebault Brian Thompson Thomas J. Tomaszek",
    "Â©1998, RTCA, Inc.",
    "James J. Treacy Barry W. Trudeau Todd Twachtmann Antony Vaudrey Jon 1. VelIe Douglas B. Vickers Bernd Volmar Larry Walker William C Wanner John C. Wauer Michael M. Webb Horace Wesley Joel Wichgers Lion Wildenburg Thomas G. Wills Ken Winell Lyle Wink Christopher J. Wolf Sandy Wyatt Sidney Ying Tom Young Thomas W. Zalesate F \nederal Aviation Administration American Airlines, Inc.",
    "Rockwell Collins Civil Aviation Authority - UK \nHoneywell Illgen Simulation Jeppesen Co. Gmbh Canadian Marconi Company F \nederal Aviation Administration Rockwell Collins ARINC, Inc. \n\nNOAA \nRockwell-Collins RLD \nUS Army Kearfott Guidance & Navigation Corp Federal Aviation Administration F \nederal Aviation Administration Honeywell, Inc. Rockwell Collins Air Line Pilots Association U. S. Navy \n\n## Appendix A Glossary",
    "## Appendix A Glossary\n\nAccuracy -- The degree of conformance between the estimated or measured value and its true value. \n\nAeronautical Information Regulation and Control (AlRAC) -- An acronym (aeronautical information regulation and control) signifying a system aimed at advance notification based on common effective dates, of circumstances that necessitate significant changes in operating practices.",
    "Aeronautical Data -- Data used for aeronautical applications such as navigation, flight planning, flight simulators, terrain awareness and other purposes, which comprises navigation data and terrain and obstacle data. \n\nAeronautical Database -- An Aeronautical Database is any data that is stored electronically in a system that supports airborne or ground based aeronautical applications. An Aeronautical Database may be updated at regular intervals.",
    "AIC -- Aeronautical Information Circular \nAlP -- Aeronautical Information Publication \n\n## Ais -- Aeronautical Information Service\n\nAnomaly -- 1) Deviation or departure from the normal or common order, form, or rule; 2) One that is peculiar, irregular, abnormal or difficult to classify.",
    "ASCII -- American Standard Code for Information Interchange Assemble -- The process of merging or compiling aeronautical data, sometimes from multiple data suppliers, into a database and establishing a baseline for subsequent processing. The assemble phase includes checking the data and ensuring that detected errors and omissions are rectified.",
    "Assurance Level - The degree of confidence that a data element is not corrupted while stored or in transit. This can be categorised into three levels: 1,2, and 3; with 1 being the highest degree of confidence. Completeness - The degree of confidence that all of the data needed to support the intended use is provided. \n\nCorrect Data -- Data meeting stated quality requirements.",
    "Correct Data -- Data meeting stated quality requirements. \n\nCorruption -- A change to previously correct data introduced during processing, storage or transmission, that causes the data to no longer be correct Cyclic Redundancy Check (CRC) -- A mathematical algorithm applied to the digital expression of data that provides a level of assurance against loss or alteration of data. For further information refer to RTCA DO-20 \n1 \nAlEUROCAE ED-77.",
    "Database -- One or more files of data structured to enable data to be extracted from the files and for them to be updated. This primarily refers to data stored electronically and accessed by computer, rather than in files of physical records. \n\nData Quality -- A degree or level of confidence that the data provided meet the requirements of the user. These requirements include levels of accuracy, resolution, assurance level, traceability, timeliness, completeness, and format.",
    "Deficiency -- The aeronautical data process is not adequate to ensure that data quality requirements are satisfied. \n\nDistribute -- The process of duplication of formatted aeronautical data into a database and the shipping and loading of the database into the target system for application. Distribution is usually achieved by transferring the data from one medium to another, with each transfer being verified.",
    "End-user -- The last user in an Aeronautical Data Chain. Aeronautical data end-users are typically aircraft operators, airline planning departments, air traffic service providers, flight simulation providers, airframe manufacturers, systems integrators, and regulatory authorities. \n\nError -- Defective or degraded data elements or lost or misplaced data elements or data elements not meeting stated quality requirements.",
    "Flight Management System (FMS) -- An on-board computerised management system that integrates aircraft performance information and positional information derived from navigation sensors with stored navigation and flight plan details and AIS data, together with manual inputs, to provide piloting instructions.",
    "Format -- The process of translating, arranging, packing and compressing a selected set of data for distribution to a specific target system. A result of this process is a data structure that is a characteristic of data quality. \n\n## Icao -- International Civil Aviation Organisation",
    "## Icao -- International Civil Aviation Organisation\n\nIntegrity -- The extent that modification of software or data can be controlled in a computer system. The assurance that a data element retrieved from a storage system has not been corrupted or altered in any way since the original data entry or latest authorised amendment. \n\nNon-conformity -- The data processor does not properly carry out the defined procedures. \n\nNon-compliance -- The data processor does not comply with this standard.",
    "Non-compliance -- The data processor does not comply with this standard. \n\nNOTAM -- Notice to Airmen Obsolete -- Documentation, data or tools that have been replaced by subsequent issues. \n\nObstacle -- Any natural or manmade fixed object which has vertical significance in relation to adjacent and surrounding features and which is considered as a potential hazard to the safe passage of aircraft.",
    "Originate The process of creating a data element or amending the value of an existing data element. \n\nOriginator -- The first organisation in an Aeronautical Data Chain that accepts responsibility for the data. For example, a State or RTCA DO-200AlEUROCAE ED-76-compliant organisation. \n\nPrecision -- The smallest difference that can be reliably distinguished by a measurement process.",
    "(See Appendix B) \nOuality -- The ability of a process or product to meet its stated requirements, that it is fit for its specified purpose. (See Appendix B) \nQuality Assurance -- The process of ensuring, by use of pre-defined methods, that pre-defined requirements of quality are incorporated in the final product. All activities and functions that affect the level of quality of a product are of concern to quality assurance.",
    "Receive - Accepting input data from a supplier (internal or external), per specified criteria. \n\n## Rna V -- Area Navigation\n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nResolution -- The smallest difference between two adjacent values that can be represented in a data storage, display or transfer system (see Appendix B). \n\n## Sarps -- Standards And Recommended Practices\n\nSelect -- The process of extracting a subset of data from a database to meet the requirements of a user.",
    "Terrain -- Natural surface of the earth excluding man-made obstacles. \n\nTimeliness - The degree of confidence that the data is applicable to the period of its intended use. \n\nTraceability -- The degree that a system or a data product can provide a record of the changes made to that product and thereby enable an audit trail to be followed from the end-user to the data originator.",
    "Translate -- The process of changing how information is expressed. For example, textual descriptions of procedures may be converted to ARlNC 424 leg types using the ARlNC 424 \ncoding rules. \n\nTransmit - A functional link whereby data is moved from one physical location to another. \n\nTransmission includes distributing and receiving. (See Distribute and Receive). \n\nUser --\nAny group or organisation within an Aeronautical Data Chain that receives data.",
    "User --\nAny group or organisation within an Aeronautical Data Chain that receives data. \n\nValidation -- The activity whereby a data element is checked as having a value that is fully applicable to the identity given to the data element, or a set of data elements that is checked as being acceptable for their purpose (See Appendix C).",
    "Verification -- The activity whereby the current value of a data element is checked against the value originally supplied. (See Appendix C) \n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## Appendixb Guidance On Defining Data Quality Requirements",
    "This Appendix provides explanatory material relating to the requirement in Section 2.3.3, item 1: \n\"The user of aeronautical data shall determine data quality requirements.\" It should not be read as establishing requirements additional to section 2. In an Aeronautical Data Chain (see Section",
    "1.5.4), it is typically the application provider who defines or co-ordinates the end-user data quality requirements. However, the final responsibility for meeting the data quality requirements remains with the end-user. For airborne applications, the approval of the avionics function and performance includes an explicit approval of the features that utilise the stored aeronautical data.",
    "These requirements are passed to the end-user to be applied when obtaining data updates. The end-user may add requirements based on intended operations. \n\nThis appendix is illustrative and provides a correlation between aircraft hazard analysis levels and the data quality assurance levels supporting the results of that analysis. \n\nNote: This appendix is illustrative and does not create requirements on software developers or data processors additional to those specified in Section 2.",
    "Section 1 of this Appendix provides guidance on the definition of data quality requirements such that the application performs its intended function. It is generally applicable to the application provider and the end-user. Section 2 of this Appendix provides guidance on passing these requirements along an Aeronautical Data Chain, through a number of data suppliers. It is generally applicable to all processors of aeronautical data. \n\n## B.1 Application Integrationiend-User Requirements",
    "## B.1 Application Integrationiend-User Requirements\n\nThe data quality requirements are defined based upon the intended function supported by the data. For example, during the approval of RNA \nV equipment, the applicant should define minimum requirements on the quality of the data to be loaded into the navigation database. Guidance is provided for each of the data quality characteristics defined in Section 2.3.2. \n\n## B.1.1 Accuracy",
    "## B.1.1 Accuracy\n\nThe required accuracy of a particular data element should be based upon its intended use. Accuracy is usually specified for data elements that are derived from measured values, and are not specified for data elements which have a defined value. For example, the location of a VOR and the height of an obstacle are measured and should have an associated accuracy requirement. The identifier associated with that VOR is defined, and does not have an accuracy requirement.",
    "Accuracy requirements should be developed in accordance with a system allocation of a higher-level accuracy requirement. \n\nFor typical navigation operations, levels of accuracy for individual data elements are defined in R \nTCA \nDO-201NEUROCAE \nED-77, Industry Requirements for Aeronautical Information. \n\n## B.1.2 Resolution",
    "The required resolution of a particular data element should be based on its intended use. Resolution only applies to data elements that are derived from measured values, and does not apply to data elements that are defined. Since the resolution may also affect the accuracy of the data, it must be considered in relation to the accuracy requirement. Once the resolution is defined, it should be incorporated into the specified data format. For typical navigation operations, the resolution of",
    "incorporated into the specified data format. For typical navigation operations, the resolution of individual data elements are defined in RTCA DO-201AlEUROCAE",
    "ED-77, Industry Requirements for Aeronautical Information.",
    "## B.1.3 Assurance Level\n\nThis standard defines the requirements for the data process. The required assurance level for the data process must be identified, based on the overall system architecture through allocation of risk. Since integrity of a process usually cannot be numerically quantified, the integrity requirement may be defined by a quality assurance level. The following assurance levels are defined to support the definition of the integrity requirement for the data process.",
    "These assurance levels are defined to be compatible with other safety analyses conducted for aircraft applications. \n\n| Data Process      |\n|-------------------|\n| Assurance Level   |\n| on State-Provided |\n| Data              |\n| (leAO)            |\n| 1                 |\n| Critical          |\n\n--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n2 \nEssential \n3 \nRoutine",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n2 \nEssential \n3 \nRoutine \n\nData Process Assurance Levels applicable to Aeronautical Information are set out in RTCA DO-201AlEUROCAE ED-77. Assurance Levels for applications of data not covered by RTCA DO-201AlEUROCAE ED-77 will need to be determined by the end-user or application provider.",
    "For applications integrated into aircraft, the required assurance level for the aeronautical data process is identified, based on the overall system architecture through allocation of risk determined using a preliminary system safetyÂ· \nassessment. Guidance on this assessment can be found in: \nSAE ARP4761 Guidelines and Methods/or Conducting the Safety Assessment Process on Civil Airborne Systems and Equipment;",
    "SAE ARP4754IEUROCAE ED-79} Certification Considerations/or \nHighly Integrated or Complex Aircraft Systems; \nJAA AMJ 25.1309 Advisory Material Joint, System Design and Analysis; \nFAA AC 25.1309-1AAdvisory Circular, System Design and \nAnalysis; \nRTCA DO-178B/ EUROCAE ED-12B} Software Considerations in \nAirborne Systems and Equipment Certification; \nRTCA DO-201A1EUROCAE ED-77} Industry Requirements/or \nAeronautical Information.",
    "RTCA DO-201A1EUROCAE ED-77} Industry Requirements/or \nAeronautical Information. \nThe failure condition categories listed below are applicable to aircraft applications, having been derived from this guidance material. The aircraft failure condition categories are:",
    "B \nCatastrophic \nprevent continued safe flight and \nlanding. \nHazardous/ \nFailure conditions that would reduce \nSevere-\nMajor \nthe capability of \nthe aircraft or the \nability of \nthe crew to cope with \nadverse operating conditions to the \nextent that there would be: \n(1) a large reduction in safety \nmargins or functional capabilities, \n(2) physical distress or higher \nworkload such that the flight crew \ncould not be relied on to perfonn \ntheir tasks accurately or completely, \nor",
    "could not be relied on to perfonn \ntheir tasks accurately or completely, \nor \n(3) adverse effects on occupants \nincluding serious or potentially fatal \ninjuries to a small number of \nthose \noccupants. \nMajor \nFailure conditions that would reduce \nthe capability of \nthe aircraft or the \nability of \nthe crew to cope with \nadverse operating conditions to the \nC \nextent that there would be, for \nexample, a significant reduction in \nsafety margins or functional",
    "extent that there would be, for \nexample, a significant reduction in \nsafety margins or functional \ncapabilities, a significant increase in \ncrew workload or in conditions \nimpairing crew efficiency, or \ndiscomfort to occupants, possibly \nincluding injuries. \nMinor \nFailure conditions that would not \nsignificantly reduce aircraft safety, \nand that would involve crew actions \nthat are well within their capabilities. \nD \nMinor failure conditions may include, \nfor example, a slight reduction in",
    "D \nMinor failure conditions may include, \nfor example, a slight reduction in \nsafety margins or functional \ncapabilities, a slight increase in crew \nworkload, such as routine flight plan \nchanges, or some inconvenience to \noccupants. \nNo Safety \nFailure conditions that do not affect \nEffect \nthe operational capability of \nthe \nE \naircraft or increase crew workload.",
    "In addition to assessing the failure condition category associated with malfunctions caused by data, it is important to detennine the required assurance level associated with loss of a function due to data. This is generally defmed by the availability requirement for an aircraft level function.",
    "For example, the availability of a precision approach capability may be defined as a major failure condition implying an equipment design assurance Level C. The data process should be consistent with the tightest assurance level requirements, either derived from the malfunction effect or availability requirement, in the approach example this would equate to a data process assurance level 2. \n\n## B.1.4 Traceability",
    "## B.1.4 Traceability\n\nUser requirements for traceability are typically stated in terms of the duration of time that specific data elements must be traceable. It is recommended that data be retained as long as the data is in use. \n\n## B.1.5 Timeliness",
    "Many data elements have an identified period for which the data is valid. The period of validity may be based upon an update period from the supplier or the underlying characteristics of the data itself. An example of an update period is when States publish aeronautical data on a 28 day AIRAC cycle. An example of the period being based on its characteristics is terrain data supporting a terrain application: the period of time for which terrain data remains acceptable should be determined during",
    "the period of time for which terrain data remains acceptable should be determined during evaluation of the system.",
    "The requirement is to use valid, current data. This responsibility rests with the end-user. The end-user may choose to discharge this responsibility by purchasing a particular set of data, based upon its declared effective period. \n\n## B.1.6 Completeness",
    "## B.1.6 Completeness\n\nCompleteness includes defining any requirements that define the mlnImum acceptable set of data to perform the intended function. One minimum set may be defined at time of equipment approval, while a larger set may be identified by the end-user.",
    "The requirement defined at time of equipment approval is typically just that there is a database that is consistent with planned operations. The requirement defined for the operation is for the database to contain a particular set of data for the area(s) where operations are intended.",
    "For many systems, database size limitations restrict the total amount of data that can be stored. In this case, selection criteria can be used to reduce the total content. This selection criteria must be consistent with the operational requirements of the end-user. For example,",
    "1) a navigation database may contain all approaches within the U.S., excluding \nall approaches to runways less than 5,000 feet long; or, \n2) a terrain database may contain terrain for a complete area with higher \nresolution for all airports with runways longer than 3,500 ft.",
    "resolution for all airports with runways longer than 3,500 ft. \nThe responsibility to have the necessary data for the areas of intended operation is placed on the end-user. The end-user may choose to discharge this responsibility by purchasing a particular set of data, based upon its declared coverage region.",
    "## B.1. 7 Format\n\nThis definition of the fonnat of delivered data must be adequate to ensure that the data, when loaded into the end application, is interpreted in a manner that is consistent with the intent of the data. The fonnat of the data will also define the transmission resolution of data. \n\n## Data Element Format B.1.7.1\n\nThere are two potential levels of fonnatting: basic data fonnat and compression techniques. Examples of the basic data fonnat include:",
    "1) definition of \nthe parameter; \n2) sign convention; \n3) units; or, \n4) coding method (e.g., binary-coded decimal, two's complement) \nFor delivery into the application, a data compression technique may be used to reduce the required amount of memory. In this case, the compression technique is part of the defined fonnat. The decompressed data must be the same as the data before compression. \n\nGenerally this assurance can be provided through tool qualification.",
    "Generally this assurance can be provided through tool qualification. \n\n## Relationship Between Data Elements B.1.7.2\n\nDefinition of relationships between data elements IS crucial to the proper application of the data for its intended function. \n\nData relationships can exist between: \n\n- \ndata characters within a data element \n- \ndata elements within a data record \n- \ndata records within the same data file \n- \ndata records and other data files \nFor RNA \nV applications, examples of each are:",
    "- \nThe elevation field in airports and runways file must have both a numeric \nvalue and a sign indication for above and below sea level; \n- \nThe navaid class field indicates whether there is a VOR and/or DME, and thus \nthose fields must be present; \n- \nWhen defining a procedure the relationship between the fixes constitute the \nprocedure. While fixes can be defined as latitudes and longitudes, they only \nhave real meaning when linked into a procedure; \n-",
    "have real meaning when linked into a procedure; \n- \nThe use of a waypoint by an airway, procedure, company route or preferred \nroute must be supported in the appropriate data file. \nInformation related to defining relationships between data elements can be found in RTCA DO-201AlEUROCAE ED-77 and ARlNC Specification 424. Based on the specifics of the application, the relationships defined in these documents may or may not be adequate. For procedures that were originally designed for RNA \nV",
    "V \nequipment, RTCA DO-201AlEUROCAE ED-77 and ARINC 424 should be adequate. In the case of inadequate definition in these documents of data element relationships for the application's intended function, specific supplemental definition should be provided.",
    "One method of ensuring the format is sufficiently defined, and is compatible, is to test database updates in a simulated environment. This method is particularly useful when coding procedures that were not originally designed to be RNA \nV \nprocedures. \n\nThis type of validation is a very effective means of ensuring the database path and published procedures are compatible. Other methods may be used, including adequate definition of the data format.",
    "## B.2 Data Supplier Requirements B.2.1 Accuracy",
    "Each data supplier must consider the accuracy provided by its suppliers, any potential changes to the accuracy introduced by the data process, and the accuracy required by the user. If the resolution of data is small relative to the accuracy requirement, and if any data translations are performed with a small processing error, it is sufficient for each data supplier in a chain to simply pass the accuracy requirement to the predecessor without modification. \n\n## B.2.2 Resolution",
    "## B.2.2 Resolution\n\nWithin the process of a data supplier, the resolution should be considered with respect to the accuracy requirement as described in Section B.2.1. \n\n## B.2.3 Assurance Level\n\nThe user requirement for integrity is passed along an Aeronautical Data Chain. It is recommended that the integrity requirement be defined in the context of an assurance level (1, 2, or 3). The application of these levels is discussed in Section C.2.3. \n\n## B.2.4 Traceability",
    "## B.2.4 Traceability\n\nThe user requirement for traceability is passed along an Aeronautical Data Chain. \n\n## B.2.S Timeliness\n\nThe user requirement for timeliness is passed along an Aeronautical Data Chain. \n\n## B.2.6 Completeness",
    "## B.2.6 Completeness\n\nIt is important that the selection criteria are co-ordinated and agreed upon with the user. Since the end-user frequently cannot readily assess the storage requirements associated with a particular set of selection criteria, the data supplier may be the one who develops this criteria in order to meet system capacity constraints. \n\n## B.2.7 Format",
    "## B.2.7 Format\n\nThe definition of the format includes the format for individual data elements and the relationship between data elements (see Section B.1.7). \n\n## Appendixc Consideration And Guidance On Compliance With Data Processing Requirements\n\nThis appendix establishes an acceptable means, but not the only means, of complying with the requirements of Section 2.4, \"Aeronautical Data Processing Requirements\".",
    "The primary objective of the data process is to supply data that meets the data quality requirements. The requirements of Sections 2.3 and 2.4 have been developed to support this objective. This appendix is organised to focus on the relationship between the procedures, the process requirements, and the identified data quality requirements. The guidance in this appendix is organised based upon the following data quality characteristics.",
    "Note: This appendix is illustrative and does not create requirements on software developers or data processors additional to those specified in Section 2. \n\n## C.I Accuracy",
    "An analysis of the data process specified in the procedures should be accomplished (see Section 2.4.1, item 8). For data originated locally, the analysis should include the accuracy and resolution of the process that originated and validated the data. For data not originated locally, the analysis must consider the accuracy and resolution delivered from the preceding data supplier. Moving and storing data does not affect accuracy, but the effects of every format/translation must be evaluated.",
    "## C.2 Assurance Level\n\nThe integrity requirement will generally be stated as a data process Assurance Level (see Appendix B). \n\nThis section describes verification and validation techniques, and explains how they relate to the assurance levels. Validation and verification may be applied to all the data or a statistically significant sample of the data. For a data quality requirement of Level 3, validation and verification are recommended but not required. \n\n## C.2.1 Validation",
    "## C.2.1 Validation\n\nValidation is the activity where a data element is checked as having a value that is fully applicable to the identity ascribed to the data element, or a set of data elements is checked as being acceptable for their purpose. \n\nThe following paragraphs describe the basic methods of validation. Any or all of these methods may be used as part of a data process. \n\n## C.2.1.1 Validation By Application",
    "## C.2.1.1 Validation By Application\n\nOne method of validation is to apply data under test conditions. In certain cases this may not be practical. Validation by application is considered to be the most effective form of validation. For example, flight inspection of final approach segment data prior to publication can be used to ensure that the published data is acceptable. \n\n## Logical Consistency C.2.1.2",
    "## Logical Consistency C.2.1.2\n\nLogical consistency validates by comparing the relationship between two different data sets (Figure C-l). For example, published headings can be compared to the computed heading between two fixes, or contour lines of adjacent cells can be compared.",
    "This method cannot completely validate the data as there is the possibility that the different data sets include the same error. Independence of the data sets substantially improves the effectiveness of this type of validation. \n\nExamples of logical consistency include: \n\n1) comparison of \nduplicate information; or, \n2) contextual relationships between data elements (related record, field and \ncharacter checks, colinearity checks). \n\n## Semantic Consistency C.2.1.3",
    "## Semantic Consistency C.2.1.3\n\nSemantic consistency validates by comparing data to an expected value or range of values for the data characteristics (Figure C-2). \n\nThis method cannot completely validate the data as there is the possibility that the data has an error that lies within the expected range. \n\nExamples of semantic consistency include:",
    "Examples of semantic consistency include: \n\n- \npresence versus absence of \ndata \n- \nfield and character context \n- \nrange limit checks \n- \ngeographic vicinity checks \n- \nuse in the declared time period of \nvalidity \n- \nfield sizes \n\n## C.2.2 Verification Techniques",
    "## C.2.2 Verification Techniques\n\nVerification is a process for checking the integrity of a data element whereby the data element is compared to another source, either from a different process or from a different point in the same process. While verification cannot ensure that the data is correct, it can be effective at ensuring that the data has not been corrupted by the data process. \n\n## C.2.2.T Digital Error Detection Techniques",
    "## C.2.2.T Digital Error Detection Techniques\n\nDigital error detection techniques can be used to detect errors during the transfer or storage of data. Examples of these techniques include cyclic redundancy checks CCRCs), parity, Hamming codes, and Reed-Solomon codes. Coding techniques can be effective regardless of the transmission media, such as computer disks, modem communication, or the Internet.",
    "While the data quality integrity requirement is specified as an assurance level, digital error detection techniques are unique in the data process in that they can be numerically evaluated. In fact, the only way to assess the performance of a particular technique is to assess its numerical performance. Therefore, Table C-I",
    "may be used to associate the data quality assurance levels to a probability of undetected corruption. These probabilities can only be applied to digital error detection techniques. They may not be applied to any other portion of the data process.",
    "| Assurance Level    | Probability    | of          |\n|--------------------|----------------|-------------|\n| undetected         | corruption     |             |\n| 1                  |                |             |\n| S;1Q-8             |                |             |\n| 2                  |                |             |\n| S;10-              |                |             |\n| 5                  |                |             |\n| 3                  | Not            | applicable. |",
    "Data Process Assurance Levels applicable to Aeronautical Information are set out in RTCA DO-201AJEUROCAE ED-?? \n\nThe underlying probability of an error occurring and the amount of the protected data should be considered when demonstrating compliance to this requirement.",
    "The most common form of error detection for navigation data is the application of a CRC. A CRC is a coding algorithm whereby a sequence of N data bits is manipulated by an algorithm to produce a block of n bits, known as the CRC, where n is less than N. A check of the integrity of the data can be performed by comparing the result of the application of the algorithm with the declared expected result. By careful choice of the algorithms employed, in conjunction with the relative values of n and",
    "By careful choice of the algorithms employed, in conjunction with the relative values of n and N, a CRC will detect a specified proportion of the potential erroneous bit patterns.",
    "Properly selected algorithms are capable of providing a probability of undetected corruption by random errors of less than 2\"\", where n is the length of the polynomial. \n\n## C.2.2.2 Feedback\n\nFeedback testing is the comparison of a data set between its output and input state \n(Figure C-3). A common method of feedback is manual confirmation, whereby data is copied to a new location and confirmed to be correct. \n\n## C.2.2.3 Independent Redundancy",
    "## C.2.2.3 Independent Redundancy\n\nIndependent redundancy testing involves processing the same data through two \n(or more) independent processors and comparing the data output of each process \n(Figure C-4). \n\n## C.2.2.4 Update Comparison",
    "Updated data can be compared to its previous version.. This comparison can identify all data elements that have changed. The list of changed elements can then be compared to a similar list generated by the supplier. A problem can be detected if an element is identified as changed on one list and not the other. This method can also be used to reduce the amount of data that is subjected to other forms of verification, focusing in on only those elements that have changed.",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n\n## C.2.3 Application Of Validation And Verification\n\nValidation and verification are both employed by a data process to ensure that data meets the associated data quality requirement for integrity. \n\n## Assurance Levell C.2.3.1\n\nDue to the critical nature of undetected errors for a process designated Levell, it is important that there is no opportunity for errors to be introduced by human error in the data process.",
    "In addition, tools that can modify the data in an undetected manner must be qualified to a level consistent with the hazardous or catastrophic failure condition. In order to determine the level of qualification, the architecture of the data process must be examined.",
    "Below are examples of process architectures supporting hazardous/catastrophic failure conditions (Levell Process). These examples can be linked to form an Aeronautical Data Chain of any length. When evaluating a Level 1 process which relies on a CRC or other coding technique, it is important to ensure that the intermediate process between the application and removal of the CRC does not contain any design errors which could generate a CRC value for invalid data. The ability of a CRC to detect",
    "any design errors which could generate a CRC value for invalid data. The ability of a CRC to detect errors can only be quantified for random errors. Note that the shaded boxes indicate applications or tools qualified consistent with the hazardous or catastrophic failure condition.",
    "The most basic Level 1 process is shown in Figure C-5 below. \n\nAssurance is provided by the originally generated eRe value and the verification of the eRe value in the end application. Both are qualified in accordance with the hazardous or catastrophic failure condition.",
    "Of significant interest is any tool which has the ability to generate the same CRC \nas was originally applied. In Figure C-6, the tool can generate that CRC value and therefore should be qualified to a level consistent with the failure condition \n(hazardous or catastrophic).",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\nTools that translate or format the data do not need to be qualified as long as the subsequent participant can recover the original format. This enables the subsequent participant to verify the eRe value and ensure that there are no undetected errors introduced by the unqualified tool.",
    "Since verification of the eRe value is only effective against random errors, it is important that the unqualified tool cannot generate a eRe value which would pass the subsequent verification. \n\nTo support traceability and immediate detection of transmission errors, the tools may generate and verify other eRe values. In this case, the tool may have to be qualified to a lower level of assurance, depending on the data quality requirements.",
    "In Figure C-7, the intermediate tools do not have the ability to generate a CRC \nvalue which would pass the subsequent verification. Therefore, these tools do not have to be qualified to a level consistent with the hazardous or catastrophic failure condition.",
    "The tools can assemble, format, distribute and receive without exposing the data to undetected errors at the end application. It is recommended that a different CRC value be generated for data before distribution and after receiving. The use of such a CRC will prevent the situation where an error is not detected until the end of an Aeronautical Data Chain. While such a detected error results in a safe situation, it is undesirable and would have to be traced back up the chain until the source of",
    "safe situation, it is undesirable and would have to be traced back up the chain until the source of the error were discovered. The tools should be qualified to a lower level, based on how they support other data quality requirements (e.g., traceability, completeness, format).",
    "Assurance is provided by the originally generated eRe value, use of a qualified tool, and the verification of the eRe value in the end application. All three are qualified in accordance with the hazardous or catastrophic failure condition. For example, the tool may be qualified using the standards ofDO-178BIEDI2B, Section 12.2 for Level A or B applications.",
    "Finally, Figure C-8 illustrates how the original CRC value can be verified using a verification qualified tool, since the tool itself cannot introduce errors in the data. \n\nThe verification tool should be qualified to a lower level, based on how they support other data quality requirements (e.g., traceability, completeness, format).",
    "--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---\n~----------------------------------------------------------------~ \nThe verification tool can be qualified to a lower standard since the tool does not have the ability to introduce errors. \n\n## Fieure C-8 Process With Qualified Verification Tool Assurance Level 2 C.2.3.2\n\nFor Assurance Level 2, validation by application is not required. \n\nHowever, application remains the most effective means of validation and can be used.",
    "However, application remains the most effective means of validation and can be used. \n\nLogical and semantic consistency may also be used as components of the overall validation. \n\nAs with Level 1 data, validation is typically accomplished by the originator of the data. Once the data is validated, verification techniques must be used to ensure that the technical content of the data is not modified at any stage of the process.",
    "Anyone or a combination of the validation methods identified in Section C.2.1 \nmay be applied. \n\nTable C-2 provides additional information on how the verification methods may be applied and states what issues must be addressed. \n\n## C.2.3.3 Assurance Level 3\n\nFor a data assurance Level 3, validation and verification are recommended but not required.",
    "Update \n- \n- \n- \nComparison \nRequires a list \nof \nmodified \nelements from \nall sources. \nSkills \ncompetency of \nindividuals \nperforming \nmanual \ncomparison \nTool \nqualification of \nany tools used \nto accomplish the comparison \nVerification \nDigital Error \nFeedback \nIndependent \nTechnique \nDetection \nRedundancy \nIssues that - Tool \n- Skills \n- Independence \nMust be \nqualification \ncompetency of \nof \nthe two (or \nAddressed \nof \nany tools \nindividuals \nmore) \nused to \nperforming \nprocesses",
    "of \nthe two (or \nAddressed \nof \nany tools \nindividuals \nmore) \nused to \nperforming \nprocesses \naccomplish \nmanual \n- Skills \nthe digital \nfeedback \ncompetency of \nerror detection - Tool \nindividuals \nqualification of \nperforming \nany tools used \nmanual \nto accomplish \ncomparison \nthe feedback \n- Tool \ncompanson \nqualification of \nany tools used \nto accomplish the comparison",
    "Table C-3 provides additional information on how the verification methods may be applied to the six phases of process defined in sections 1.6.5.2 through 1.6.5.3. \n\nThe first row includes phases that involve moving data from one physical location or medium to another. Examples are copying files to a removable disk and facsimile of written data. Assembling of data is the process whereby it is moved from different locations to a common location.",
    "The second row includes phases that involve transforming data from one data structure to another. Examples include transforming data from written form to binary form.",
    "Verification \nDigital Error \nFeedback \nIndependent \nUpdate \nTechnique \nDetection \nRedundancy \nComparison \nApplications \nEffective, \nFeedback is an \nIndependent \nUpdate \nto: \nassurance can \neffective means of redundancy is an \ncomparison is an \nReceive Phase \nbe \nverifying data \neffective means of effective means of \nAssemble \nnumerically \nafter \nverifying data \nverifying data \nPhase \ndemonstrated. \nmoving/storing. \nduring \nduring \nSelect Phase \nManual feedback \nmoving/storing.",
    "demonstrated. \nmoving/storing. \nduring \nduring \nSelect Phase \nManual feedback \nmoving/storing. \nmoving/storing. \nDistribute \ncan be used as \nPhase \npart of \na Level C \nprocess. \nApplication to: \nNot \nFeedback can be \nIndependent \nUpdate \nTranslate \napplicable. \nused when \nredundancy is an \ncomparIson IS an \nPhase \ntransforming data. \neffective means of not an effective \nFormat Phase \nIn order to \nverifying manual \nmeans of \ncompare the \ntransformations. \nverifying \noutput of \nthe",
    "In order to \nverifying manual \nmeans of \ncompare the \ntransformations. \nverifying \noutput of \nthe \nFor automated \ntransformation, as \ntransformation to \ntransformations, \nthe transformation \nthe input, it is \nthe tool that \ncould introduce \nnecessary to \nperforms the \nthe same error in \ntransform one or \ntransformation \nboth updates. \nboth to a common \nshould be \nHowever, use of \nform (e.g., \nqualified. \nupdate \n| ASCII).             | comparIson can     |",
    "However, use of \nform (e.g., \nqualified. \nupdate \n| ASCII).             | comparIson can     |\n|---------------------|--------------------|\n| Therefore,          | provide some       |\n| feedback provides   |                    |\n| assurance           |                    |\n| verification only   |                    |\n| if                  | provided the prior |\n| the means           |                    |\n| of                  | update has been    |\n| transformation for  | validated (by      |",
    "| of                  | update has been    |\n| transformation for  | validated (by      |\n| the verification is |                    |\n| application).       |                    |\n| independent         |                    |\n| of                  | the                |\n| means               |                    |\n| of                  |                    |\n| transformation      |                    |\n| that is being       |                    |\n| verified.           |                    |",
    "## C.3 Traceability\n\n| Configuration management    |\n|-----------------------------|\n| requirements.               |\n\n## C.4 Timeliness\n\nThe data process achieves timeliness through data configuration management.",
    "## C.4 Timeliness\n\nThe data process achieves timeliness through data configuration management. \n\nTimeliness can be assured by including any limits on the effective period with the data elements. These limits may be associated with individual data elements or data sets. If the effective period is defined for a data set, it should account for the effective dates of all of the individual data elements. \n\n## C.S Completeness",
    "## C.S Completeness\n\nIt is important that no data is inadvertently discarded. The skills competency of individuals who select and assemble data must be assured. Tools that assemble or select data must be qualified for this purpose. \n\n## C.6 Format\n\nThe procedures should ensure that the output data will comply with the specified format. Compliance is typically accomplished by qualification of the tool that generates the delivered product. \n\n## C.7 Error Reporting",
    "The procedures should define how detected errors are reported. As identified in Section 2 of this standard, errors should be traced back to the source. If data that contains an error is delivered, it is very important that the user is also notified of the error. The action taken in event of a detected error should be based upon the type of error: some errors may be very significant, requiring immediate notification. The procedures should identifY how an error is categorised, and based on that",
    "notification. The procedures should identifY how an error is categorised, and based on that categorisation what action is taken. Three significant issues that must be addressed in each case are:",
    "- \nTo whom are the errors reported? \n- \nHow quickly are errors reported? \n- \nDoes the process exclude the data containing the error, is it delivered with the \nerror, or is an attempt made to correct the error? \nIn addition, the process should record all error reports.",
    "It is beneficial to periodically review the error reports to identifY trends in data errors that may be correctable. The error report should identifY any notification of error from a user, any errors determined during validation or verification, and any errors reported to a prior data supplier. \n\n--`,``,````,`,`,``,``,````,`````-`-`,,`"
  ]
}