RTCA, Incorporated 
1140 Connecticut Avenue, N.W., Suite 1020 
Washington, DC 20036-4001 USA 

## Standards For Processing Aeronautical Data

Prepared by SC-181 
Â© 1998, RTCA, Inc. 

Copies of this document may be obtained from RTCA, Inc. 

1140 Connecticut Avenue, NW, Suite 1020 
Washington, DC 20036-4001 USA 
Telephone: 202-833-9339 
Facsimile: 202-833-9434 
Internet: www.rtca.org Please call R 
TCA for price and ordering information. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## Foreword

This report was prepared by Special Committee 181 (SC-181) and approved by the RTCA Program Management Committee (PMC) on September 28, 1998. 

RTCA, Incorporated is a not-for-profit corporation formed to advance the art and science of aviation and aviation electronic systems for the benefit of the public. The organization functions as a Federal Advisory Committee and develops consensus based recommendations on contemporary aviation issues. RTCA's objectives include but are not limited to: 

- 
coalescing aviation system user and provider technical requirements in a manner that helps 
government and industry meet their mutual objectives and responsibilities; 
- 
analyzing and recommending solutions to the system technical issues that aviation faces as it 
continues to pursue increased safety, system capacity and efficiency; 
- 
developing consensus on the application of pertinent technology to fulfill user and provider 
requirements, including development of 
minimum operational performance standards for electronic 
systems and equipment that support aviation; and 
- 
assisting in developing the appropriate technical material upon which positions for the International 
Civil Aviation Organization and the International Telecommunication Union and other appropriate 
international organizations can be based. 
The organization's recommendations are often used as the basis for government and private sector decisions as well as the foundation for many Federal Aviation Administration Technical Standard Orders. 

Since RTCA is not an official agency of the United States Government, its recommendations may not be regarded as statements of official government policy unless so enunciated by the U.S. government organization or agency having statutory jurisdiction over any matters to which the recommendations relate. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## Executive Summary

The RTCA Technical Management Committee established Special Committee 181 (SC-181) 
with the following tenns of reference. 

- Special Committee 181 shall investigate the processes involved in the processing, 
control and loading of 
aeronautical databases, and produce guidance to ensure that: 
a) 
The integrity of 
the civil aviation authority and the flight management 
system created source data is not degraded. 
b) 
The databases are compatible with the type of 
equipment that will use them. 
c) 
The databases are updated in ways that ensure that a) and b) remain current 
and valid. 
- Special Committee 181 shall review current practices used in defining aeronautical 
data and recommend any changes needed to provide improved operational 
effectiveness of 
airborne navigation systems that use stored databases. 
- Special Committee 181 shall co-ordinate its work with the European Organisation for 
Civil Aviation Equipment, Working Group 13 (EUROCAE WO 13). The results will 
be the combined effort of 
these two organisations, RTCA SC 181IEUROCAE WO 13. 
After reviewing the previous efforts of SC-lS7 and the documents that were published as a result of that effort, it was detennined that the basic infonnation contained in RTCA DO-200, 
"Preparation, Verification, and Distribution of User-Selectable Navigation Data Bases" and RTCA DO-201, "User Recommendations for Aeronautical Infonnation Services" was still applicable but needed updating to support new technology and the expanding scope of aeronautical data covered by this document. It was agreed that the guidelines covering the production of the aeronautical databases (RTCA DO-200) should be expanded to provide a more structured approach to the extremely important issues of data quality and data integrity management. It was also agreed that aeronautical infonnation needed to support the efficient operation of computer-based systems had now become a requirement rather than a recommendation. The work of RTCA SC-181IEUROCAE WOl3 has resulted in two new documents: 

a) 
DO-200AlED-76, "Standards for Processing Aeronautical Data"; and, 
b) 
DO-20 
1 
AlED-77, "Industry Requirements for Aeronautical Infonnation" 
These documents are submitted to the aviation community as a collection of disciplines necessary to provide assurance that the production of aeronautical databases meets the high integrity required for safe flight. 

This document provides a recommended minimum standard for the processing of aeronautical data. It is applicable to all phases of the aeronautical data process, from origination through acceptance and application by the end-user. It is intended to be used by organisations seeking approval of the methodes) they use to process or manipulate data. As a result, the document is structured in a manner, which will assist the organisation to: 

1) relate material obtained from the relevant regulatory authority to the requirements set 
forth herein; and 
2) determine if 
its processing methodes) meets the requirements. 
The document is divided as follows: 
Section 1 -- is an introductory section which provides: 

- 
information on the purpose and scope of 
the document; 
- 
an explanation of 
how to use and apply the document; 
- 
a list of 
baseline documents used in the development of 
the document; 
- 
an explanation of 
the concept that the end-user of 
the data has the ultimate 
responsibility for defining requirements and ensuring that requirements are met; and, 
- 
an explanation of 
the concepts of 
data quality characteristics, required data quality, 
assuring quality through quality management, Aeronautical Data Chains and the 
functional links in those chains. 
Section 2 - defines the requirements. It establishes the users' responsibility for defining their data quality requirements. It provides requirements for aeronautical data processing and quality management, as it pertains to the aeronautical data process. Organisations intending to demonstrate compliance with this document will need to review this section to ensure that they meet all requirements relevant to their data processing activities. 

Section 3 -- describes a method, but not the only method, that can be used to demonstrate compliance with the requirements. States or approval authorities may determine that an application for approval using alternative methods of demonstrating compliance may also be acceptable. 

Appendix A - a glossary of 
terms and abbreviations used in the document; 
Appendix B - provides guidance on defining data quality requirements in support of 
those 
requirements expressed in Section 2; and 
Appendix C - provides guidance and further details on the methods available to demonstrate 
compliance. 
This page intentionally left blank:. 

## 1 Purpose And Scope 1.1 Introduction

This document provides the minimum standards and guidance for the processing of aeronautical data that are used for navigation, flight planning, terrain awareness, flight simulators and for other applications. 

Such data would be passed on to the user as a database. The standard provides requirements that should be used to develop, assess change, and support implementation of data processing quality assurance and data quality management. When applied, the standard will provide the user with assurance of the level of quality that can be associated with the processed data, e.g. aeronautical database. 

## 1.2 How To Use This Document

This document represents a consensus that has been reached within the aviation community. It has been written so that it may be applied by the regulatory authorities as an acceptable means of ensuring that aeronautical data maintains the required data quality and supports its intended application. It does not, in itself, have any authority over organisations responsible for processing aeronautical data. 

This document is intended to address the specific issues of the aeronautical data process. It assumes that those organisations have in place an acceptable quality management system and does not attempt to specify requirements other than those associated with the aeronautical data process. 

This document uses the term "shall" to identify requirements within this standard, which can be traced to particular aspects of the aeronautical data process. The term "should" is used where a procedure is recommended as an improvement to the aeronautical data process or to support demonstration of compliance, over and above the minimum requii'ements specified in this standard. 

Section 1 is informative, and defines the basic concepts associated with the aeronautical data process, including that of suppliers, users, and aeronautical data chains. Section 1 also describes some of the unique aspects of aeronautical data chains and examples are given as they apply to navigation and terrain data. This information is not intended to limit the potential application of this standard to other types of aeronautical data. 

Section 2 contains the requirements for the aeronautical data process. In support of this section, Appendix B provides guidance on defining the data quality requirements. Appendix C provides guidance for demonstrating compliance with the requirements of Section 2 of this standard. 

Section 3 specifies the objectives, procedures and reports associated with the audit of the aeronautical data process, in demonstrating compliance with Section 2 of this standard. 

## 1.3 Scope

This document provides a minimum standard for all phases of the data process applicable to the processing of aeronautical data, including quality assurance and quality management. The standard will provide guidance to assess compliance and determination of the levels of process assurance. This standard supports the development and application of aeronautical databases, where an aeronautical database is a collection of data that is organized and arranged for ease of electronic storage and retrieval in a system that supports airborne or ground based aeronautical applications. It is a complementary standard to those for data and applications listed in Section 1.3.2. 

## 1.3.1 Definition Of Terms

The definitions of terms used in this document are provided in a glossary in Appendix A. 

Several terms have been given specific and more restricted meanings than may be understood from general use, and full appreciation of the intended differentiation between terms that are often used as synonyms in nontechnical publications will be helpful to the reader. Accordingly, the definitions of accuracy, precision, resolution, integrity, quality, validation and verification are amplified in Appendix B, where their interrelationships are discussed. 

## 1.3.2 Reference Documents

1. ICAO Annex 4, International Standards and Recommended Practices -
Aeronautical Charts 
2. ICAO Annex 11, International Standards and Recommended Practices -Air 
Traffic Services 
3. ICAO Annex 14, International Standards and Recommended Practices -
Aerodromes and Heliports 
4. ICAO Annex 15, International Standards and Recommended Practices -
Aeronautical Information 
5. RTCA DO-201A1EUROCAE ED-77, Industry Requirementsfor Aeronautical 
Information 
6. RTCA DO-236IEUROCAE ED-75, Minimum Aviation System Performance 
Standards: Required Navigation Performance for Area Navigation 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

7. ICAO Doc 8126, Aeronautical Information Services Manual AN/872 
8. ICAO Doc 9613, Manual on Required Navigation Performance AN/937 
9. AEEC, ARINC *Specification* 424, Navigation System Data Base 
10. ICAO Doc 9674, *World Geodetic System* 1984, (WGS-84) AN/946 
11. RTCA DO-178BIEUROCAE ED-12B, Software Considerations in Airborne 
Systems and Equipment Certification 

## 1.4 Application Of Standard

The ultimate responsibility of ensuring that data meets the quality for its intended application rests with the end-user of that data. To a large extent, this responsibility can be met by obtaining data from a supplier accredited against this standard by an appropriate organisation. This does not alter the supplier's responsibility for any functions performed on the data. 

This standard is intended to assist the originators, the users and the regulatory authorities in meeting their responsibilities. To provide the most flexibility in applying this standard, two different types of applications are foreseen: 

1. an organisation meets all of the applicable requirements of this document, 
applied to a particular set of data quality requirements. This type of approval 
is tailored to organisations that process a limited amount of data, always of 
the same type and always to meet the same user requirements; or, 
2. an organisation meets all of 
the applicable requirements of 
this document for a 
general class of data. The quality management procedures are sufficient to 
develop a data process for a new set of data quality requirements, without 
further evaluation. This type of approval is tailored to organisations that 
process a large amount of data for a number of different users, with different 
user requirements. 

## 1.5 Concepts 1.5.1 Data Quality

The quality of data is its ability to satisfy the requirements for its safe application in the end system. The quality of aeronautical data and the way that it is processed is characterised by: 

1. Accuracy; 
2. Resolution; 
3. Assurance Level; 
4. Traceability; 
5. Timeliness; 
6. Completeness; and, 
7. Format 
The seven characteristics listed above are defined in Appendix B. The degree that a data element meets the user's requirements determines its fitness for use. 

## 1.5.2 Required Data Quality

Airspace users, air traffic service providers and national aviation authorities have developed guidelines on the levels of risk that are judged to be acceptable for different phases of flight. These are defined either on the basis of risk pertaining to a specific operation, such as a landing, or as a risk of failure per flight hour. 

From an analysis of the potential causes of failure, and the allowable risk, it is possible to derive the allowable contribution to failure of the individual components of the system. 

Based upon such a breakdown, the user of aeronautical data is able to determine both the accuracy and resolution required for each data element and the necessary level of assurance that the data have not been corrupted (assurance level). 

The timeliness requirements are determined by the need to ensure that the data is applicable to the application period and the lead times required to ensure that it can be used in the stated validity period. 

A baseline set of such requirements for aeronautical data are set out in R 
TCA DO-
201AlEUROCAE ED-77. 

## 1.5.3 Assuring Quality 1.5.3.1 Quality Management

The nature of the aeronautical data process combines detailed data, with a multilevel data environment and related processes and procedures. In this end-to-end environment, data is: originated at its source(s), assembled, processed and formatted to meet the requirements of its end application(s) (see Figurel-l). A 
Quality Management Process is that which provides the framework upon which the procedures for doing the job are developed, managed, controlled, assessed, and changed. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## Traceability 1.5.3.2

An essential part of any Quality Management Process is the need to validate and verify data. Where it is found that data does not meet the stated quality requirements it is necessary to determine the sources of the error to allow corrective action to be taken. To achieve this, data should be traceable to the supplier and to the next user, and errors should be traceable to their root causes. 

Note: The requirement for traceability extends from its original publication 
      through to its application. The aim of 
                                              such traceability is to ensure that all 
      anomalies or errors detected in use can be traced back to their origin, and 
      the resolution of 
                         the anomalies promulgated to all others who might be 
      affected. 

## Aeronautical Data Chains 1.5.4 1.5.4.1 Overview

An "Aeronautical Data Chain" is a conceptual representation of the path that a set, or element, of aeronautical data takes from its creation to its end use. With an aeronautical data chain, as in a physical chain, each link is connected to its adjacent links. The symbolic links that make up an aeronautical data chain, may be as broad as organisations or departments within organisations, or, as refined as individuals or specific equipment. These are described in the following sections. 

Many different aeronautical data chains may contribute to a collection of data that is used by an end-user. When reading the sections of this document that refer to chain "links" or "participants", envision the functions performed by the organisation, and how the organisation handles aeronautical data to determine applicability to a particular situation. 

An aeronautical data chain is a series of interrelated links wherein each link provides a function that facilitates the origination, transmission and use of aeronautical data for a specific purpose. There are typically five major types of links in a chain and a chain can be of varying length as a link type can occur more than once. The functional links are; Origination, Transmission, Preparation, Application Integration, and End-Use of aeronautical data. A chain should be viewed as a circular flow of information whereby the end use of aeronautical data determines what aeronautical data should be originated. 

Each of the functional links in a chain may be performed by a single organisation, or distributed among various separate organisations. For example, a state could originate, prepare, and integrate aeronautical information for a specific application prior to end use. Conversely, two examples of distributed aeronautical data chains are: 

1. an approach procedure may be originated by a State and issued into the public 
domain. Another organisation may process ( 
compile) the approach 
information, translate the information into coding (e.g. ARINC 424) and 
transmit the result to a Flight Management Computer (FMC) application 
provider. The Flight Management Computer (FMC) application provider, in 
turn, processes the data into a proprietary format that allows the target FMC 
application to access the data. The resultant data is then integrated. 
into the 
target FMC application; or, 
2. terrain data may be originated by a State and issued into the public domain. 
Another organisation may process (compile) the terrain data, translate, format, 
and transmit the result to the terrain application provider. The application 
provider, in turn, processes the data into a proprietary format that allows the 
target application to access the data. The resultant data is then integrated into 
the target application. 
Two examples of aeronautical data chains, from origination of data through to the application of data by end-users are shown in Fiz:ures 1-1 and l.:.2.. The types of organisations included in the flow are: 

1. State Aeronautical Information Services or Terrain Data Agencies; 
2. Data Service Providers; 
3. Application Providers; and, 
4. End-users. 
Each of the boxes shown in Figures I-I and 1-2 can be associated with one of the organisations listed above. Within each box (organisation), an aeronautical data chain can have many links as each organisation may perform one or all of the functions that comprise chain links. The arrows between boxes represent the transmission link although the transmission link can occur within a box or between processes. 

Each of the function links in an aeronautical data chain is described below. Each of the descriptions includes the logical definition of the function, a historical perspective on who performs the described function, and some relevant existing regulation and/or guidance on requirements for performing the described function. 

## Aeronautical Data Origination 1.5.4.2

Origination is a functional link whereby values, names or other information are determined and assigned to required data elements for use in a subsequent functional link. For example, surveying to determine the elevation of the end of a runway, and calculating co-ordinates for a waypoint that is the intersection of two existing airways fall under the Aeronautical Data Origination functional link. 

Any and/or all participants in an aeronautical data chain may originate aeronautical data. Historically, most aeronautical data is originated by individual States. Other originators may supplement State originated data or originate data that is independent of the State. Examples of other chain participants that may originate aeronautical data include, but are not limited to, airlines, aircraft manufacturers, airport authorities, defence mapping agencies, and communication service providers. 

## Commentary On Navigation Data:

The International Civil Aviation Organisation (ICAO) Standards and 
Recommended Practices (SARPs) for Aeronautical Information Services 
(AIS), published as Annex 15 to the Convention on International Civil 
Aviation, requires each Contracting State to provide an AIS. 
                                                                    Each 
Contracting State must take all necessary measures to ensure that the 
aeronautical information/data it provides is adequate, of 
                                                         required quality 
(accuracy, resolution and integrity) and provided in a timely manner for 
the entire territory that the State is responsible for. It is incumbent upon 
the national aviation authority in each State to arrange for the timely 

proviSion of 
            required aeronautical information to the AIS by each of 
                                                                      the 

State services associated with aircraft operations. The order of 
                                                                  accuracy 
for aeronautical data is specified in Annex 11 - Air Traffic Services and 
Annex 14, Volume I - Aerodromes and Volume II - Heliports. The 
specifications for publication and charting resolution is specified in Annex 
15 and 
       Annex 4 - Aeronautical Charts,. 

In accordance with Article 38 of 
                                 the Convention, Contracting States are 
required to notify ICAO of any differences between their national 
regulations and 
               practices and the International Standards contained in the 
Annexes, including Annex 15. Those differences are then published as 
Supplements to the Annexes. In addition, States are required to provide a 

list of 
        significant differences to related SARPs in a form that would enable 
the user to differentiate readily between the requirements of 
                                                                                  the State and 
the related ICA 0 provisions. 

Each State publishes permanent aeronautical information in an 
Aeronautical Information Publication (AlP). 
                                        This is conventionally a 
paper document, containing text, tables and charts, a transition to the 
provision of electronic aeronautical information by States is planned 
Permanent changes to the AlP are published as AlP Amendments. 
Temporary changes of long duration (three months or longer) and 
information of short duration that contains extensive text/graphics are 
published as AlP Supplements. Information of 
                                         a temporary nature and 
short duration is provided in the form of 
                                    Notice to Airman (NOTAM). 
Information that does not qualifY for inclusion in the AlP, or in a NOTAM, 
is published as Aeronautical Information Circular (AIC). 

AlP Amendments and AlP Supplements that contain operationally 
significant information 
                      are published in 
                                         accordance 
                                                     with 
                                                          the 
internationally accepted 
                        Aeronautical Information Regulation and 
Control (AlRAC) system. This system is based on the internationally 
agreed series of common effective dates at intervals of 28 days. The 
information must be distributed by the AIS at least 42 days in advance of 
the effective date with the objective to reach the recipient at least 28 days 
in advance of 
           the effective date. 

Commentary on terrain data: 

No ICAO recommendations have been published for the collection, 
processing, publication and distribution of 
                                      terrain data. Therefore, it is 
incumbent upon the responsible agencies to ensure that the required 
terrain information originated by a number of 
                                         different data providers is 
collected, processed, published and distributed to all interested aviation 
users according to their requirements. 

Terrain data is not subject to the ICAO AlRAC revision cycle. Terrain 
data changes may be triggered by better surveys, higher resolution data, 
additional data availability and detected errors. 

## 1.5.4.3 Aeronautical Data Transmission

Transmission is a functional link whereby data is moved from one physical location to another. This is a link that joins other processes and/or organisations and typically occurs many times in a data chain. For example~ State generated data being issued into the public domain, either on paper or electronically, electronic information being moved from one computer to another, and telephone 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
calls to relate information from one individual to another all fall under the Aeronautical Data Transmission functionallinlc There are many types of electronic transmission, such as copying files onto computer diskettes, modem communication, electronic mail and file transfer over the Internet. The primary issues associated with transmitting data are detecting errors and ensuring the data configuration management requirements are satisfied. 

Another consideration is the security of the transmission: e.g., protecting the data from modification by an external entity, or minimising the potential for accepting invalid data. Transmission is a function performed by all chain participants. Electronic transmission protocols typically involve some type of error checking to ensure the integrity of the transmission. 

## Aeronautical Data Preparation 1.5.4.4

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
Preparation is a functional link whereby a variety of aeronautical data elements are analysed, translated, compiled, and/or formatted to produce data configured for use in a subsequent functional link. The data may be received from one or more chain participants and may be in different configurations and formats. In the following examples, all activities fall under the Aeronautical Data Preparation functional link: 

1) processing information for an AlP amendment, entering AlP information into 
a database, translating a chart or textual depiction of an approach procedure 
into ARINC 424 coding, converting an electronic text file into a binary 
format, and reformatting compiled data into a product specific format; and, 
2) acquiring charts or digital terrain elevation files, scanning and digiti 
sing the 
chart, entering terrain elevation in a database, analysing consistency of terrain 
contours, converting to a reference co-ordinate system, compiling with 
previous values for the same area, formatting compiled data into a product 
specific format. 
Any participant in an aeronautical data chain can prepare aeronautical data. 

Typically, this is done by data originators, data service providers and application integrators. States issue volumes of information at a single time (such as AlP 
amendments). The information contained in the AlP is configured and formatted prior to its release. Data service providers combine existing data with data they have originated for the configuration and format requirements of target applications and/or required intermediate steps. Prior to use in a target application, aeronautical data may be prepared by multiple organisations. 

## 1.5.4.5 Aeronautical Data Application Integration

Application integration is a functional link in the process whereby data, in an application specific configuration and format, is made available to the target application. Two examples of the Aeronautical Data Application Integration functional link are loading information from a media storage device, such as a floppy disk, into the system's memory and filing a chart in a manual, for use inflight. 

Aeronautical information is usually integrated into an application by the specific application provider or the end-user. 

## 1.5.4.6 End-Use Of Aeronautical Data

End-use is a functional link for accessing and acting upon the output of an application. For example, recalling a list of arrival transitions on an FMS, then selecting and flying the appropriate one; or selecting a route in a flight planning system, then receiving and flying the appropriate path both fall under the end-use of aeronautical data. As an additional example, having an alert in the cockpit, due to a potential conflict with terrain, also falls under the end-use of aeronautical terrain data. Aeronautical data end-users are typically aircraft operators, airline planning departments, air traffic service providers, flight simulation providers, airframe manufacturers, systems integrators, and regulatory authorities. 

## 1.5.5 A General Aeronautical Data Processing Model 1.5.5.1 Overview

Of the Aeronautical Data Chain functional links described in Section 1.5.4 above 
(including sub-paragraphs 1.5.4.2 through 1.5.4.6), only the requirements for Aeronautical Data Preparation and Aeronautical Data Transmission are addressed in this document, see Section 2. Requirements for the other three functional links 
(origination, application integration, and end-use) are outside the scope of this document. 

Within the Aeronautical Data Preparation functional link there are four phases: 

1. Assemble 
2. Translate 
3. Select 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

4. Format 
Each participant in an Aeronautical Data Chain who processes data defines interfaces (requirements) with prior and subsequent chain participants. Each organisation therefore performs the Aeronautical Data Transmission function. 

Within the Aeronautical Data Transmission functional link there are two phases: 

1. Receive 
2. Distribute 
The applicability of this document to an Aeronautical Data Chain is illustrated in Figure 1-3. The figure also depicts the phases associated with the Aeronautical Data Preparation and Aeronautical Data Transmission functional links. These phases are described below. Figure 1-4 depicts a general Aeronautical Data Processing Model and the data flows between the phases of the Aeronautical Data Preparation and Aeronautical Data Transmission functional links. 

## 1.5.5.2 Aeronautical Data Transmission: Receive Phase

The receive phase involves the reception, verification and validation of data. 

Verification of received data involves checks that ensure the integrity of the transmitted data. Validation involves checks of the data for applicability to its identity or as appropriate for its application. If errors, omissions or inconsistencies are identified, they are reported to the data supplier for correction and tracked by the receiving organisation to ensure that the deficiency is corrected. 

## 1.5.5.3 Aeronautical Data Preparation: Assemble Phase

The assemble phase involves the collection and collation of data from various suppliers. 

The assemble phase may result in a database that will meet the requirements of the next link in the chain. In the early stages of an Aeronautical Data Chain, for example, within a national AIS organisation, this may involve assembling inputs from surveyors, procedure designers and other services responsible for originating aeronautical data. In the later stages, it may involve assembling inputs from different chain participants that have already performed an Aeronautical Data Preparation function and translating the data into a format that supports the next process' requirements. 

Checks are carried out to ensure that the assembled data meets the quality requirements. If errors, omissions or inconsistencies are identified in the assembled data, they are reported to the responsible data supplier for analysis and correction and are tracked by the assembling organisation to ensure that the deficiency is corrected, or recorded for potential notification to the next participant in the chain. 

The source, accuracy, resolution and reported integrity of each data element, together with details of any changes made to received data, need to be recorded to assist in any future audit activity. 

## 1.5.5.4 Aeronautical Data Preparation: Translate Phase

The translate phase involves changing how information is expressed. 

For example, textual descriptions of procedures may be converted to ARINC 424 leg types using the ARINC 424 coding rules. 

Checks are carried out to ensure the integrity of the original data is maintained after translation. 

Note: The assemble and translate phases are typically combined 

## 1.5.5.5 Aeronautical Data Preparation: Select Phase

This phase involves selecting specific data elements from the collection of aeronautical data produced by the assemble phase. The output from the select phase is a subset of the original collection that is matched to the data quality requirements of the next functional link in an Aeronautical Data Chain. 

During the select phase, checks are made to ensure that the subset collection of data elements is consistent with the original collection and that no individual data elements that are needed for completeness have been omitted. A procedure will normally exist for identifying the source of any deficiencies that are found and for 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
taking corrective action. Such corrective action may include co-ordination with the prior and/or subsequent chain participant, and may require additional iterations through the receive and assemble phases. 

## Aeronautical Data Preparation: Format Phase 1.5.5.6

The format phase involves converting the selected data sub-set into a format that is acceptable to the next functional link in the chain. This may take the form of the ARINC 424 standard format for the transfer of data for navigation, flight planning, simulator use; or a proprietary format for loading in a target system; or another agreed format. 

Checks are made to ensure that the data elements are compatible with the format selected. 

The source of every error is identified in order that appropriate corrective action can be taken. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
An integrity protection scheme that meets the minimum requirements for the data, such as the Cyclic Redundancy Check (CRC), is employed to protect the user from undetected errors once verification and validation have been successfully completed. 

The choice of the error detection scheme depends upon the requirements of the client as well as the risk of corruption posed by the storage and transfer. 

## 1.5.5.7 Aeronautical Data Transmission: Distribute Phase

The distribute phase completes the processing data model and forms part of the transmission link in an Aeronautical Data Chain. This phase involves the delivery of the formatted data sub-set to users. Examples of delivery media are magnetic or optical media, solid state devices, or direct computer-to-computer links. These transfer methods allow automatic verification checks to be made using the integrity check values that resulted from the format phase. Where the distribute phase involves a number of discrete transfers, such verification checks need only be performed at the final transfer to ensure that no data loss or degradation has occurred. Additional protection may be provided within the specific distribution applications for part or all of the distribute phase. 

During the distribution process, checks are carried out to ensure that the distributed data meets the user criteria and that there are no media errors. If errors or omissions are identified, these are reported to the appropriate participant in the processing phase and procedures are followed to ensure that the deficiencies are corrected and recorded for potential notification to the end-users of the data. 

## 2 Requirements 2.1 Introduction

As stated in Section 1 the nature of the data process leads to the necessity to implement techniques and procedures throughout the entire process to ensure the aeronautical data meets quality requirements. Such techniques and procedures are called a "Quality Management" process. The following section addresses these data quality, process, and quality management requirements. If any participant's process claims to meet these requirements, it is necessary to demonstrate compliance (refer to Section 3) with these requirements. 

When the achievement of the data quality depends upon the quality of data obtained from a previous participant, then either the data accepted from the previous participant must be validated to the required level, or an assurance of data quality must be sought from that previous participant. For the majority of aeronautical data there is no benchmark against which the quality of data accepted from a previous link can be validated. The need to obtain assurance of the data quality will therefore normally flow back through the system until it reaches the originator of each data element. Consequently, reliance must be placed upon the use of appropriate procedures in every stage of the process. 

## 2.2 Compliance Plan

A compliance plan shall be prepared to document how requirements for processing aeronautical data will be accomplished. The plan shall address all aspects of the aeronautical data process carried out by the organisation choosing to comply with this standard. It shall identify: 

1. a definition of 
data quality requirements; 
2. a definition of 
aeronautical data processing requirements; 
3. a definition of 
quality management requirements; 
4. the identification of those responsible for compliance with the requirements; 
and, 
5. declaration of 
standards that are used. 

## 2.3 Defining Data Quality Requirements 2.3.1 Overview

All participants in an Aeronautical Data Chain must ensure that data quality characteristics are correctly established for the data's intended usage, and that these data quality requirements are clearly documented. 

## 2.3.2 Data Quality Characteristics

The data shall have the agreed data quality, characterised by: 

1. the accuracy of 
the data; 
2. the resolution of 
the data; 
3. the confidence that the data IS not corrupted while stored or m transit 
(assurance level); 
4. the ability to determine the origin of 
the data (traceability); 
5. the level of 
confidence that the data is applicable to the period of intended use 
(timeliness); 
6. all of 
the data needed to support the function is provided (completeness); and, 
7. the format of 
the data meets the user requirements. 

## 2.3.3 User

The user of aeronautical data shall: 

1. determine data quality requirements, See Appendix B; 
2. base the data quality of any particular data element upon the most restrictive 
requirement for its application; 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

3. assure the quality requirements are attained. (This duty may be discharged by 
the use of data from a data supplier, accredited against this standard by an 
appropriate organisation); 
4. determine the nature of 
action to be taken in the event of 
discovery of 
an error 
or inconsistency in the data; and, 
5. be responsible for establishing their requirement for being notified of data 
alteration. 

## 2.3.4 Supplierlprocessor

The following requirements apply to a data supplier/processor: 

1. The supplier/processor shall provide data that meets the agreed user 
requirements. 
2. The supplier/processor shall have a system for handling problems reported 
during data processing, and those reported by the user after delivery of the 
data. 
3. All problems reported with the data shall be analysed and any errors or 
anomalies, resolved and documented. 
4. All errors or anomalies detected in the data shall be resolved prior to delivery. 
5. Information concerning any errors or anomalies found in the data after it has 
been delivered, shall be made available to all affected users. 
6. The means by which errors or anomalies are resolved shall be reported to all 
affected users. 

## 2.3.5 Documentation Requirements (User/Supplier)

The following requirements apply to documentation: 

1. The data quality requirements shall be documented. 
2. The delivery format requirements shall be documented. 
3. Documentation shall be maintained that identifies all the suppliers of data, 
used by the organisation, and the approval status of each. For navigation data, 
an approved supplier is either a State or a RTCA DO-200AlEUROCAE ED-
76-compliant supplier. 

## 2.4 Aeronautical Data Processing Requirements 2.4.1 Data Processing Procedure Requirements

The Data Processing Procedures shall define: 

1. 
the means used to confirm that the data has been received without 
corruption; 
2. 
the means by which data is assembled; 
3. 
the means used to ensure that stored data is protected from corruption; 
4. 
the method of 
origination for all data that is originated locally; 
5. 
the means used to confirm that data that is originated locally has not been 
corrupted prior to being stored; 
6. 
the means by which validation of any data element is to be performed. This 
shall include: 
a) 
when the supplier is not approved, the means by which an 
appropriate validation can be performed; 
b) 
when multiple suppliers are available for a data element, the means 
by which differences between them are determined and resolved; 
and, 
c) 
when separate data elements have a defined relationship, the means 
by which this relationship is confirmed and any anomalies are 
resolved; 
7. 
the action to be taken when data fails a verification or validation check; 
8. 
the method to be used to evaluate degradation of accuracy when the 
resolution of a data element is reduced, or the data is translated into a 
different co-ordinate system or unit of 
measurement; 
9. 
the requisite skills and competencies necessary to perform each procedure; 
10. 
the tools required for the procedure; 
11. 
the method to be used to verify received data; 
12. 
the method by which data quality is preserved; 
13. 
the method by which the user is assured that, whenever the resolution of a 
data element is changed, or the data value is translated, the accuracy and 
resolution of 
the new value meets the data quality requirements; and, 
14. 
the method to be used to provide the user with the ability to verify that the 
data received by the user has not been corrupted. 

## 2.4.2 Data Alteration Communication Requirement

A user shall not alter the data from any supplier without informing the data originator of the change and endeavouring to receive concurrence in a timely manner. Altered data shall not be transmitted to the user if the originator rejects the alteration. Records shall be kept of all alterations and shall be made available to all subsequent users on their request. This requirement only applies to the alteration of the data, and does not apply to assembling, translating, selecting, or formatting the data. For example, defining a path other than that associated with the procedure, deleting a fix that is published as part of the procedure, or changing the name of a fix that was named by the data originator are all considered to be data alterations. 

## 2.4.3 Data Configuration Management

The objectives of data configuration management are to: 

1. ensure that data configuration controls have been implemented to provide 
assurance that data values in delivered data products are applicable to the 
declared period of 
validity; 
2. support the requirement for traceability of 
each data element to its source; 
3. reduce the vulnerability of the data processing activities to loss or corruption 
of 
stored data, regardless of 
the media or system used to store the data; and, 
4. reduce the vulnerability of the data processing activities to unintentional 
deviations from requirements of one user introduced by meeting the 
requirements of 
another user. 

## 2.4.3.1 Data Configuration Management Plan Requirements

The data configuration requirement activities shall be defined and documented in a Data Configuration Management Plan. The plan shall identify all data to be placed under configuration management. It shall include: 

1. all delivered data products; and, 
2. all data that are identified in the planning process as required to be stored to 
ensure that the production process can recover from data loss or data 
corruption. 

## 2.4.3.2 Data Configuration Management Requirements

The following requirements apply to the data placed under configuration management. Each distinct version of a data element shall be assigned a unique identification. The data element identification shall be contained within the data element, as well as being used as a physical label attached to any portable storage medium used to hold the data elements. 

The configuration management procedures shall ensure that a data element cannot be changed without changing the data element identification. 

Records shall be maintained that identify the data content of all data elements in order to support traceability. 

These records shall be sufficient to allow the following to be established: 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

1. that a data value has not been separated from its correct label; 
2. the start and end dates of 
the period of 
validity of 
the data element; 
3. the date of 
production of 
the data element; 
4. the supplier of 
each data value contained within the data element; and, 
5. the procedures used to produce the data element. 
A copy of each data element shall be retained for a period determined by the Configuration Management Plan. 

The method of storage, and the numbers of copies held, shall be such that: 

1. the integrity of 
each data element can be assured for the entire period that it is 
to be retained; and 
2. due attention is given to protection against physical damage and degradation. 

## 2.4.4 Skills And Competencies

The objectives of skills management are to: 

1. 
establish the skills required for each step of 
the process; and, 
2. 
ensure that personnel assigned to perform data processing have the necessary 
skills, competencies, and knowledge of 
the procedures. 

## Skills And Competencies System Requirements 2.4.4.1

Procedures shall be established that defme the means that personnel may acquire or maintain the skills and competencies required for the applicable procedure. 

Skills and competencies can be obtained from a variety of means, such as basic education, formal academic training, vocational courses, on-the-job training, or supervised accumulation of experience. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
Appropriate records of skills and competencies shall be maintained so that the qualifications of personnel assigned to perform specific procedures can be confirmed. 

Short-falls in skills and competencies shall be identified and corrective actions shall be taken. 

## 2.4.5 Aeronautical Data Tool Qualification

Tools (e.g. software) can be used to automate the activities associated with an aeronautical data process. Tool qualification is the process by which assurance is achieved that tools employed will neither introduce errors into the data nor degrade integrity or traceability. Tool qualification should be done within the context of the tool's intended use. 

Commentary: 

The scope of 
             the tool qualification will depend upon the data quality requirements 
and the role of the tool in the aeronautical data process. 
                                                                A tool used for 
production/modification of data will typically require a more rigorous 
qualification process than a tool used 
                                      for verification of 
                                                         data. 
                                                                This is necessary 
to ensure that the operation of 
                              the production/modification tool will not introduce 
errors. 

The objectives of 
                 tool qualification are: 

1. to demonstrate that the tool complies with the user's intended requirements; 
and, 
2. to ensure that the tool provides equivalence to any activities that it automates, 
and that the tool qualification is commensurate with the tool's intended use, or 
the data production process. 

## 2.4.5.1 Applicability Of Tool Qualification

Qualification of the tool is needed when data processes are eliminated, reduced or automated by the use of a tool without the output being verified. The following requirements apply equally to tools obtained "off the shelf' Of developed by the data processor either as a stand-alone product or as a module within an existing product. 

1. Each proposal for a new tool, or for a modification of 
an existing tool, shall be 
reviewed to determine whether the tool is required to undergo qualification. 
2. Where a decision is made that qualification is not required, justification for 
that decision shall be documented. 

## 2.4.5.2 Tool Qualification Plan

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
The tool qualification plan shall describe the tool qualification process and shall identify: 

1. the tool requirements; 
2. the tool qualification procedures; 
3. the tool configuration management procedures; 
4. the tool qualification documentation requirements; 
5. the applicable quality management procedures; and, 
6. those responsible for the qualification process, including the authority vested 
in them. 

## Tool Requirements 2.4.5.3

The Tool Requirements for the tool shall be defined and shall include: 

I. the functionality of 
the tool; 
2. the performance of 
the tool; 
3. a description of 
the tool's operational environment; and, 
4. user information, such as installation guides and user manuals. 

## Tool Qualification Procedures 2.4.5.4

The tool qualification procedures shall specify: 

1. The means by which it is ensured that the data output from the tool has the 
required data quality. This could be achieved by review, analysis or the 
execution of 
a comprehensive set of 
test procedures. 
2. The means by which it is ensured that the tool satisfies the Tool 
Requirements. 

## Tool Configuration Management 2.4.5.5

The tool configuration management process shall provide: 

1. a unique identification for each distinct version of 
a tool; 
2. the means for convenient availability/visibility of 
the tool version; 
3. the ability to consistently replicate or regenerate a particular version of the 
tool; 
4. a change control process which establishes recording, evaluation, resolution 
and approval of changes throughout the tool development and the tool's life; 
and, 
5. a secure environment for physical archiving, recovery and control for 
configured items. 

## Tool Qualification Documentation Requirements 2.4.5.6

For tools utilised in aeronautical data processes, documents and reports shall be maintained to show that the tool qualification activities have been completed satisfactorily. If modifications or changes are made to the tools, additional qualification activities and supporting documentation may be necessary. 

## Quality Management 2.5

The prerequisite to the quality management requirements is the adoption of a set of documented procedures that cover all aspects of aeronautical data processing. 

These have been defined in the preceding sections. Supporting these procedures are quality management procedures that ensure that: 

1. 
data accepted from a supplier meets the agreed data quality requirements; 
2. 
valid data processing procedures are applied; 
3. 
procedures are adhered to and there is no unauthorised deviation from the 
procedures; and, 
4. 
reviews and controls are in place to ensure quality. 
The means used to specify the quality management requirements is not intended to be prescriptive. Compliance can be demonstrated by any quality management structure that meets the requirements of this document. 

In the following sections, the phrase "plans and procedures" includes the following: 

1. 
compliance plan; 
2. 
data quality requirements; and, 
3. 
data processing, including: 
a) 
procedures; 
b) 
configuration management; 
c) 
skills and competencies; and, 
d) 
tools. 

## 2.5.1 Quality Management (Qm) Procedure Requirements

The QM procedures shall: 

1. define the criteria used for the review of plans and procedures, including the 
maximum interval between reviews; 
2. define the criteria used for the review of personnel skill records including the 
maximum interval between reviews; 
3. define the criteria used for the review of qualified tools, including the 
maximum interval between reviews; 
4. identify who will have the authority to approve plans and procedures; 
5. identify who will have the authority to certify that personnel have satisfied 
skill and competency requirements; and, 
6. identify who will have the authority to authorise (qualify) tools for use. 
Note: There is no requirement for all plans and procedures to be reviewed at the 
same periodic rate. 

## 2.5.2 Quality Management Control

All plans and procedures, including changes, shall be reviewed and approved prior to their application as described in the QM procedures. This review shall include a review of the ability of data suppliers to supply the new data with the required data quality, if applicable. 

The current version of the approved procedures is referred to as the authorised version of the procedures. 

If unauthorised deviations from the procedures are discovered, corrective action shall be taken. The corrective action may include changing the procedures and/or the skills competency requirements. 

All personnel who carry out any of the procedures shall be qualified to apply those procedures. The personnel shall have access to the authorised version of the procedures. If changes to the procedures are approved, the personnel shall be notified of the changes. Obsolete versions of documents shall not be used. 

All tools, including updated versions of tools, shall be reviewed and approved prior to their application as described in the QM procedures. 

Records of procedures, personnel and tools shall be kept to allow identification of the procedures, personnel and tools employed in the production of each delivery of data to a client. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## 2.5.3 Ltevielv

Records of all reviews shall be maintained. The records shall: 

1. identify the date of 
the review; 
2. identify who conducted the review; and, 
3. identify any non-conformities or deficiencies and how they are resolved. 

## 2.5.3.1 Event-Driven

The plans and procedures shall be reviewed when there is a proposal to supply new data, changes in the procedures (e.g. for improvements) and changes in any tools. Where such a review identifies that changes to the procedures are required, these shall be implemented prior to initial delivery of the new data. This review shall include an evaluation of the ability of data suppliers to supply the new data with the required data quality. 

The records of skill shall be reviewed for new personnel or personnel assigned new tasks. Personnel shall be authorised as having the necessary skills before participating in the data process. 

Each new or modified tool must undergo qualification as described in Section 
2.4.5. 

When a data error is detected, either internally or reported by users, action shall be taken to correct the procedures, skills, or tools to ensure that the error will not be repeated. 

## 2.5.3.2 Periodic

All plans and procedures that define the data processing and quality management requirements shall periodically be reviewed as defined in the QM procedures to ensure their continuing ability to support the data quality objectives. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
The records of the skill for personnel on the various data processing tasks shall periodically be reviewed as defined in the QM procedures. The review shall confirm that the personnel have the required skills identified in the data processing procedures. 

Tools shall periodically be reviewed as defined in the QM procedures to confirm the continuing ability of the tool to meet the data quality requirements. 

If the responsibility of achieving data quality is partially discharged by receiving data from an accredited supplier, the accreditation of suppliers against this standard shall periodically be confirmed. 

All records of detected data errors, both those detected internally and those reported by users, that are attributed to the local processing and maintenance of data, shall be reviewed periodically, as defined in the QM procedures, to consider implications on the data processing procedures or QM procedures. If action is taken as a result of a review, the action shall be recorded. 

All periodic reviews shall include a review of all problems recorded during the use of the procedures, personnel, or tool and all recorded data errors attributed to the subject of the review. The impact of any deficiencies or limitations on the quality of the aeronautical data shall be assessed and corrective action shall be taken if necessary to ensure that data meets the data quality requirements. 

## 2.5.4 Quality Records

A quality record is a document that furnishes objective evidence demonstrating conformance to specific requirements and/or the effective operation of a quality management system. Quality records may be in the form of any type of media, such as hard copy or electronic media. 

Quality records are also used to identify if procedures need to be modified to correct deficiencies. 

Where procedures require that records be kept: 

1. 
retention times of 
such records shall be established and recorded; 
2. 
records shall be legible and identifiable to the product involved; and, 
3. 
records shall be retrievable from reliable facilities that minimise loss and 
provide a low probability of 
deterioration. 

## 2.5.5 Management Reviews

The records described in Section 2.5.4 shall be reviewed by the level of management responsible for meeting the data quality requirements. 

Reviews shall: 

1. confirm that the documented plans and procedures associated with quality 
assurance have achieved the required levels of 
data quality, and; 
2. evaluate the need for corrective and preventive actions. 
The results of such reviews shall be recorded. 

## 3 Compliance 3.1 Demonstration Of Compliance

All organisations claiming compliance with the standards of RTCA DO-
200AlEUROCAE ED-76 shall demonstrate such compliance to the applicable sections. Compliance is normally demonstrated by audit but other methods may be acceptable as determined by the supplier and the affected organisation (for example, the user of the supplied data or a regulatory authority). This section focuses on audit as the means of demonstrating compliance. 

An audit of compliance shall be a systematic examination against all of the requirements of this document. The audit may be conducted against another document that contains these requirements. Audits should not lead to an increase in the scope of quality functions solely to support the audit. 

The audit can be carried out by an external organisation (for example the user of the supplied data or a regulatory authority) or delegated to the data supplier as an internal function when authority to do so is conveyed by an appropriate external organisation. The review shall be carried out by personnel independent of those having direct responsibility for carrying out the procedures. 

It is important to note that the audit does not result in a transfer of responsibility to achieve quality from the processing function to the auditing function. The auditor is responsible only for determining conformity with the processes and procedures that govern the Aeronautical Data Chain tasks being performed. The supplier is responsible for compliance with requirements of the standard which may be this document or another approved standard consistent with this document. 

## 3.2 Audit Objectives

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
The audit shall confirm that: 

1. authorised versions of all plans, and procedures associated with data quality 
assurance, the processing of aeronautical data, and quality management 
requirements (as defined in Section 2) are available; 
2. controls exist to ensure that the plans, and procedures associated with data 
quality assurance, the processing of 
aeronautical data, and quality management 
requirements are followed; and, 
3. the quality system meets all requirements as defined in Section 2, and that any 
compliance deviations have been documented and tracked. 
4. procedures exist for the management of changes to the data processing 
procedures, and that they provide assurance that revised data processing 
procedures are capable of 
meeting the stated quality requirements. 

## Audit Procedures 3.3

The auditing procedures shall: 

1. be documented and maintained by the auditor; and, 
2. define the criteria for determining the need for an audit to take place. This 
includes the number and types of changes to procedures that shall require an 
audit to be conducted and the frequency that periodic audits are to be 
conducted. 
The procedures shall ensure that all aspects of the data processing system and the quality management system are subject to audit on the basis of elapsed time since previous audit and upon the occurrence of a major change. The audit of adherence to the procedures may be executed in a progressive and incremental manner. 

Where the procedures allow the audit to be performed by incremental audit of different parts of the data processing or quality management system, the justification for such an approach shall be documented, and regularly reviewed to ensure that the justification remains valid. 

Note: It is recommended that the maximum time between audits whether total or 
incremental be not more than one year. 

## Audit Reports 3.4

All audit observations shall be documented. The auditor shall review all observations to determine which observations are to be reported as nonconformities. The auditor shall ensure that non-conformities are documented in a clear concise manner, and that they are supported by evidence. Non-conformities should be identified in terms of the specific requirements of this document that have not been met. A copy of the audit report shall be delivered to the organisation being audited. 

Non-conformities shall be categorised as follows: 

1. Major Non-Conformity - The process does not comply with the requirements 
of this standard and immediate corrective/preventive action is required. A 
major non-conformity typically results when a significant quality management 
system requirement has either not been defined, documented, or implemented. 
A major non-conformity indicates a systemic failure of the quality 
management system. 
2. Minor Non-Conformity - The process continues to comply with the 
requirements of 
this standard but requires corrective action within a specified 
time period. 
A minor non-conformity typically results from objective 
evidence that a portion of the quality management system is not consistently 
implemented, or needs improvement in order to more completely fulfil the 
requirements. 
3. Observation - The process does not require corrective action. An observation 
is a statement of 
opinion by the auditor for consideration. 

## Membership Rtca Special Committee *1811* Eurocae Working Group 13 Navigation Standards

Northwest Airlines UK Civil Aviation Authority Co-Chairs Frank Alexander Geoffrey Burtenshaw Federal Aviation Administration 

## Secretary Bruce Decleene

Delta Airlines Douglas Aircraft Company Texas Instruments, Inc. 

Boeing Commercial Airplane Co. 

SAIC-SCT Group Members and Advisors Robert Ainsworth Romel Aminmadani Mike Amundsen William J. Anacker Robert K. Anoll Ken Ashton John W. Bail Claude Baileau Roger Baker Pat Banks Clayton Barber Jean Baron John Barrer Carlo Bassani Jerry M. Battenhouse Michael Beamish Martin Beckmann August H. Beining Vincent L. Bencivenga Gerald E. Bendixen Chris Benich Steve Bergner Joel Berkoukchi Jack Bertron Hughes Bidel Robert W. Billings Richard J. Biro William A. Blake Ronald M. Bolton Phil Boughton Carl F. Bowlen Jerry Bradley UK National Air Traffic Servo Narco Avionics, Inc. 

Air France Eldec Corporation US Airways Garmin International, Inc. 

DGAC/SPAe The MITRE Corporation Meridanana Airlines Air Line Pilots Association Pelorus Navigation Systems, Inc. 

Trimble Navigation Hughes Aircraft Company VLB Associates Rockwell Collins Honeywell, Inc. 

Cableair Sextant A 
vionique Federal Aviation Administration Sextant A 
vionique GARMIN International Rockwell-Collins Federal Aviation Administration National Oceanic Service Air Transport Association of America Federal Aviation Administration System Resources Corporation The MITRE Corporation NOS/ACC 
Consultant AlliedSignal Aerospace Co Inc United States Air Force Honeywell, Inc. 

UK - Civil Aviation Authority Federal Aviation Administration DGAC/STNA 
Sikorsky Aircraft Trimble Naviagation Ltd Rannoch Corporation Delco Systems Ops Sextant A 
vionique Sextant A 
vionique Air Economics Group, Inc. 

Atlantic Coast Airlines Rockwell Collins, Inc. 

U. S. Navy Air Line Pilots Association Smiths Industries NIMA St. Louis STASYS Ltd. 

Universal Avionics Systems Corp. 

F 
ederal Aviation Administration EUROCONTROL 
Trimble Navigation Universal Avionics Systems Corp. 

Aerospatiale Aerospatiale International Air Transport Assn. 

AlliedSignal Aerospace Co Inc ARINC, Inc. 

SAIC 
GARMIN International, Inc. 

National Geodetic Survey Rockwell-Collins Adsystech, Inc. 

Federal Aviation Administration U. S. Air Force. 

Honeywell, Inc. 

F 
ederal Aviation Administration Federal Aviation Administration Federal Aviation Administration Canadian Marconi Company F 
ederal Aviation Administration Honeywell Suzanne Bradley Charles Branch Joel Breazeale Frank 1. Brem Grover C. Brown Dave Burdon Ludmilla Burt Susan J.M. Cabler Philippe Caisso 
1. 1. Carson Gerry Carson Rick 1. Cassell Claude Castelbou Bruno Cazali Philippe Chaix George C. Chang Vincent Chirasello George A. Cobley Glenn Colby Kevin Comstock Michael R. Cramer Jack Crawford John Curtis Charles F. Cusack Evan R. Darby Jeremy Davidson Darrell W. Davis James M. Davis Hughes de Beco Gilles DeCevins Louis Desmarais Kelly Dillard John C. Dobyne Chip Dorman John Doughty David Doyle Gary Dwen Paul Ebert David W. Eckles Malcolm C. Emerick Jary Engels Jim Enias Robert Erikson Pat Fair Sohel Fares Robert Fischer Terry Flaishans Crown Communications, Inc. 

A 
vroTec, Inc. 

Continental Air Lines, Inc. 

All Nippon Airways Co., Ltd. 

U. S. Navy Douglas Aircraft Company Airbus Industrie AlliedSignal Aerospace Co. Inc. 

System Resources Corp. 

BFGoodrich Avionics Systems Rosemont Aerospace Inc. 

Honeywell, Inc. 

Raytheon Systems Company AlliedSignal Aerospace Co Inc Mesaba Airlines Sterling Software ARINC, Inc. 

Canadian Marconi Company United Airlines, Inc. 

International Air Transport Assn. 

Transport Canada EUROCAE 
F 
ederal Aviation Administration Rockwell Collins BFGoodrich Avionics Systems Air Line Pilots Association Honeywell, Inc, Honeywell, Inc Federal Aviation Administration United Parcel Service Honeywell, Inc. 

Jeppesen Co. Gmbh British Airways Federal Aviation Administration EUROCAE 
Innovative Solutions International Federal Aviation Administration Transport Canada Rockwell Collins AlliedSignal Aerospace Co. Inc. 

Hughey & Phillips Mesaba Airlines Advanced Nav. & Position Corp. 

Trimble Navigation The MITRE Corporation Federal Aviation Administration Pat Fletcher Ken Foote George Fox Shunichi Furue Ian T. Gallimore Neil Gallon Hermann Ganz Robert Gaul Robert Geary Blake Getson John Ginn R. David Girts Rocklin R. Gmeiner David Goddard Kluus Goersch Tsuyoshi Goka Roger S. Goldberg Michael Gordon-Smith Tom Graff Tore R. Granaas Jim Gregory Francis Grimal Roy Grimes Donald Grimm Brett Gundlach Charles K. Guy Jim Haberstock Allan Hart Michael Hawthorne Robert Hilb John Hillier Bodot Hohnberg Ian Hudson Alfred E. Hughes Geoff Hunt M. Stephen Huntley Tom Imrich Douglas Ingold Richard Jinkins Robert Johns Peter H. Johnson Peter Johnson Dale E. Johnson Rudolph Kalafus Elliott D. Kaplan Robert 1. Kelly 
Â©1998, RTCA, Inc. 

U. S. Air Force Transport Canada II Morrow, Inc. 

Federal Aviation Administration J 
eppesen-Mentor ALP 
AlUS Airways National Aeronautics & Space Administration Northstar Technologies Illgen Simulation Technologies, Inc EUROCONTROL 
Air Line Pilots Association Federal Aviation Administration F 
ederal Aviation Administration Jeppesen Sanderson A 
vidyne Corporation F 
ederal Aviation Administration Atlantic Coast Airlines Jeppesen Sanderson DGAC/STNA 
Smiths Indu. Aero & Defense Sy Aerospatiale F 
ederal Aviation Administration Litton Aero Products F 
ederal Aviation Administration Seagull Technology, Inc. 

The MITRE Corporation F 
ederal Aviation Administration Federal Aviation Administration NOAA 
F 
ederal Aviation Administration RTCA, Inc. Federal Aviation Administration Boeing Commercial Airplane Group All Nippon Airways Co., Ltd. 

Mayflower Communications Rockwell Collins NASA Ames Research Center ICAO 
Aurcraft Electronics Association Litton Systems, Aero Products Div. 

NATS, Ltd. 

F 
ederal Aviation Administration Northwest Airlines, Inc. 

Air Line Pilots Association Smiths Indu. Aero & Defense Sy Jeff King Alexander Korolov Waldemar R. Krolak Marvin A. Kumley Thomas 1. Laginj a John Laurin Simon Lawrence Victor Lebacqz Scott C. Lewis Robert W. Lilley C. M. Loghides Howard A. Long George Lyddane Michael Magrogan Chet Mason Simon Matthaws Leslie McCormick Sean McCourt Barry T. McDaniel Veronique Melet Pete Mellema Jean-Pierre Metivier Jeff Meyers Charles Michaels Natalie Miller Joseph A. Miller Satish C. Mohleji Jim Moon Carl Moore John R. Moore Robert L. Morton Harold Moses William M. Mosley David A. Nakamura Y 
oshinobu Nakanishi Peter Nicolaides Gary Owen Everett Palmer Aleksandar Pavlovic Terry L. Pearsall Richard Perrin Bernard Perry Ivan Petrenko William F. Petruzel Mike Pfleiderer William J. Phaneuf Bill Phebus AlliedSignal Aerospace Co Inc AvCom, Inc. 

Deering Sys. Design Consultant ARINC Incorporated NIMA 
American Trans Air EUROCONTROL 
F 
ederal Aviation Administration Austrian Airlines Base Southwest Airlines Company Delta Airlines, Inc. Boeing Commercial Airplane Company Raytheon Aircraft E-Systems Montek F 
ederal Aviation Admininistration Interstate Electronics Corp. 

Jeppesen Sanderson, Inc. 

Canadian Marconi Company Russell Systems Inmarsat F 
ederal Aviation Administration Rockwell Collins National Aeronautics & Space Administration National Business Aviation Association Boeing Commercial Airplane Group Honeywell Inc Innovative Solutions Intern'l Rockwell-Collins Continental Air Lines, Inc. 

Jeppesen Co. Gmbh Ohio University Universal Avionics Systems Corp, WA 
Soaring Society of AmericaiFIA 
Boeing Commercial Airplane Co. 

AlliedSignal Aerospace Co Inc Crown Communications, Inc Delta Airlines, Inc. Federal Aviation Administration Canadian Marconi Company Jeppesen Sanderson Aviso, Inc. 

Experimental Aircraft Association Defense Concept Associates, Inc. 

Jeppesen Sanderson Honeywell Inc Litton Rockwell Collins Gerard Philippe R. Andrew Pickens H. Robert Pilley Paul J. Prisaznuk Lynne E. Puetz Mary A. Randall Roland C. Rawlings Albert J. Rehmann Erich Reiterer Mike Rickman Tim V. Rider Michael Ripp Glyn K. Romrell F. Charles Rosario Alan Ross Rudolph M. Ruana William Ruhl William M. Russell Fintan R. Ryan Rosanne Ryburn Ellen L. Schaefer Herbert W. Schlickenmaier Gerald C. Schroeder Robert W. Schwab Lou Selk Ralph D. Sexton Dennis Shaver Samuel L. Shirck Ralf Sieprath Trent A. Skidmore Sam Slentz Bernald S. Smith George Sotolongo Christine Stahl Ken Staub Keith Stover Robert I. Stuckert John Studenny Tim Sukle Abdul M. Tahir Donald J. Taylor Tom S. Teetor Jim E. Terpstra Yannick Thebault Brian Thompson Thomas J. Tomaszek 
Â©1998, RTCA, Inc. 

James J. Treacy Barry W. Trudeau Todd Twachtmann Antony Vaudrey Jon 1. VelIe Douglas B. Vickers Bernd Volmar Larry Walker William C Wanner John C. Wauer Michael M. Webb Horace Wesley Joel Wichgers Lion Wildenburg Thomas G. Wills Ken Winell Lyle Wink Christopher J. Wolf Sandy Wyatt Sidney Ying Tom Young Thomas W. Zalesate F 
ederal Aviation Administration American Airlines, Inc. 

Rockwell Collins Civil Aviation Authority - UK 
Honeywell Illgen Simulation Jeppesen Co. Gmbh Canadian Marconi Company F 
ederal Aviation Administration Rockwell Collins ARINC, Inc. 

NOAA 
Rockwell-Collins RLD 
US Army Kearfott Guidance & Navigation Corp Federal Aviation Administration F 
ederal Aviation Administration Honeywell, Inc. Rockwell Collins Air Line Pilots Association U. S. Navy 

## Appendix A Glossary

Accuracy -- The degree of conformance between the estimated or measured value and its true value. 

Aeronautical Information Regulation and Control (AlRAC) -- An acronym (aeronautical information regulation and control) signifying a system aimed at advance notification based on common effective dates, of circumstances that necessitate significant changes in operating practices. 

Aeronautical Data -- Data used for aeronautical applications such as navigation, flight planning, flight simulators, terrain awareness and other purposes, which comprises navigation data and terrain and obstacle data. 

Aeronautical Database -- An Aeronautical Database is any data that is stored electronically in a system that supports airborne or ground based aeronautical applications. An Aeronautical Database may be updated at regular intervals. 

AIC -- Aeronautical Information Circular 
AlP -- Aeronautical Information Publication 

## Ais -- Aeronautical Information Service

Anomaly -- 1) Deviation or departure from the normal or common order, form, or rule; 2) One that is peculiar, irregular, abnormal or difficult to classify. 

ASCII -- American Standard Code for Information Interchange Assemble -- The process of merging or compiling aeronautical data, sometimes from multiple data suppliers, into a database and establishing a baseline for subsequent processing. The assemble phase includes checking the data and ensuring that detected errors and omissions are rectified. 

Assurance Level - The degree of confidence that a data element is not corrupted while stored or in transit. This can be categorised into three levels: 1,2, and 3; with 1 being the highest degree of confidence. Completeness - The degree of confidence that all of the data needed to support the intended use is provided. 

Correct Data -- Data meeting stated quality requirements. 

Corruption -- A change to previously correct data introduced during processing, storage or transmission, that causes the data to no longer be correct Cyclic Redundancy Check (CRC) -- A mathematical algorithm applied to the digital expression of data that provides a level of assurance against loss or alteration of data. For further information refer to RTCA DO-20 
1 
AlEUROCAE ED-77. 

Database -- One or more files of data structured to enable data to be extracted from the files and for them to be updated. This primarily refers to data stored electronically and accessed by computer, rather than in files of physical records. 

Data Quality -- A degree or level of confidence that the data provided meet the requirements of the user. These requirements include levels of accuracy, resolution, assurance level, traceability, timeliness, completeness, and format. 

Deficiency -- The aeronautical data process is not adequate to ensure that data quality requirements are satisfied. 

Distribute -- The process of duplication of formatted aeronautical data into a database and the shipping and loading of the database into the target system for application. Distribution is usually achieved by transferring the data from one medium to another, with each transfer being verified. 

End-user -- The last user in an Aeronautical Data Chain. Aeronautical data end-users are typically aircraft operators, airline planning departments, air traffic service providers, flight simulation providers, airframe manufacturers, systems integrators, and regulatory authorities. 

Error -- Defective or degraded data elements or lost or misplaced data elements or data elements not meeting stated quality requirements. 

Flight Management System (FMS) -- An on-board computerised management system that integrates aircraft performance information and positional information derived from navigation sensors with stored navigation and flight plan details and AIS data, together with manual inputs, to provide piloting instructions. 

Format -- The process of translating, arranging, packing and compressing a selected set of data for distribution to a specific target system. A result of this process is a data structure that is a characteristic of data quality. 

## Icao -- International Civil Aviation Organisation

Integrity -- The extent that modification of software or data can be controlled in a computer system. The assurance that a data element retrieved from a storage system has not been corrupted or altered in any way since the original data entry or latest authorised amendment. 

Non-conformity -- The data processor does not properly carry out the defined procedures. 

Non-compliance -- The data processor does not comply with this standard. 

NOTAM -- Notice to Airmen Obsolete -- Documentation, data or tools that have been replaced by subsequent issues. 

Obstacle -- Any natural or manmade fixed object which has vertical significance in relation to adjacent and surrounding features and which is considered as a potential hazard to the safe passage of aircraft. 

Originate The process of creating a data element or amending the value of an existing data element. 

Originator -- The first organisation in an Aeronautical Data Chain that accepts responsibility for the data. For example, a State or RTCA DO-200AlEUROCAE ED-76-compliant organisation. 

Precision -- The smallest difference that can be reliably distinguished by a measurement process. 

(See Appendix B) 
Ouality -- The ability of a process or product to meet its stated requirements, that it is fit for its specified purpose. (See Appendix B) 
Quality Assurance -- The process of ensuring, by use of pre-defined methods, that pre-defined requirements of quality are incorporated in the final product. All activities and functions that affect the level of quality of a product are of concern to quality assurance. 

Receive - Accepting input data from a supplier (internal or external), per specified criteria. 

## Rna V -- Area Navigation

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
Resolution -- The smallest difference between two adjacent values that can be represented in a data storage, display or transfer system (see Appendix B). 

## Sarps -- Standards And Recommended Practices

Select -- The process of extracting a subset of data from a database to meet the requirements of a user. 

Terrain -- Natural surface of the earth excluding man-made obstacles. 

Timeliness - The degree of confidence that the data is applicable to the period of its intended use. 

Traceability -- The degree that a system or a data product can provide a record of the changes made to that product and thereby enable an audit trail to be followed from the end-user to the data originator. 

Translate -- The process of changing how information is expressed. For example, textual descriptions of procedures may be converted to ARlNC 424 leg types using the ARlNC 424 
coding rules. 

Transmit - A functional link whereby data is moved from one physical location to another. 

Transmission includes distributing and receiving. (See Distribute and Receive). 

User --
Any group or organisation within an Aeronautical Data Chain that receives data. 

Validation -- The activity whereby a data element is checked as having a value that is fully applicable to the identity given to the data element, or a set of data elements that is checked as being acceptable for their purpose (See Appendix C). 

Verification -- The activity whereby the current value of a data element is checked against the value originally supplied. (See Appendix C) 
--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## Appendixb Guidance On Defining Data Quality Requirements

This Appendix provides explanatory material relating to the requirement in Section 2.3.3, item 1: 
"The user of aeronautical data shall determine data quality requirements." It should not be read as establishing requirements additional to section 2. In an Aeronautical Data Chain (see Section 
1.5.4), it is typically the application provider who defines or co-ordinates the end-user data quality requirements. However, the final responsibility for meeting the data quality requirements remains with the end-user. For airborne applications, the approval of the avionics function and performance includes an explicit approval of the features that utilise the stored aeronautical data. 

These requirements are passed to the end-user to be applied when obtaining data updates. The end-user may add requirements based on intended operations. 

This appendix is illustrative and provides a correlation between aircraft hazard analysis levels and the data quality assurance levels supporting the results of that analysis. 

Note: This appendix is illustrative and does not create requirements on software developers or data processors additional to those specified in Section 2. 

Section 1 of this Appendix provides guidance on the definition of data quality requirements such that the application performs its intended function. It is generally applicable to the application provider and the end-user. Section 2 of this Appendix provides guidance on passing these requirements along an Aeronautical Data Chain, through a number of data suppliers. It is generally applicable to all processors of aeronautical data. 

## B.1 Application Integrationiend-User Requirements

The data quality requirements are defined based upon the intended function supported by the data. For example, during the approval of RNA 
V equipment, the applicant should define minimum requirements on the quality of the data to be loaded into the navigation database. Guidance is provided for each of the data quality characteristics defined in Section 2.3.2. 

## B.1.1 Accuracy

The required accuracy of a particular data element should be based upon its intended use. Accuracy is usually specified for data elements that are derived from measured values, and are not specified for data elements which have a defined value. For example, the location of a VOR and the height of an obstacle are measured and should have an associated accuracy requirement. The identifier associated with that VOR is defined, and does not have an accuracy requirement. 

Accuracy requirements should be developed in accordance with a system allocation of a higher-level accuracy requirement. 

For typical navigation operations, levels of accuracy for individual data elements are defined in R 
TCA 
DO-201NEUROCAE 
ED-77, Industry Requirements for Aeronautical Information. 

## B.1.2 Resolution

The required resolution of a particular data element should be based on its intended use. Resolution only applies to data elements that are derived from measured values, and does not apply to data elements that are defined. Since the resolution may also affect the accuracy of the data, it must be considered in relation to the accuracy requirement. Once the resolution is defined, it should be incorporated into the specified data format. For typical navigation operations, the resolution of individual data elements are defined in RTCA DO-201AlEUROCAE 
ED-77, Industry Requirements for Aeronautical Information. 

## B.1.3 Assurance Level

This standard defines the requirements for the data process. The required assurance level for the data process must be identified, based on the overall system architecture through allocation of risk. Since integrity of a process usually cannot be numerically quantified, the integrity requirement may be defined by a quality assurance level. The following assurance levels are defined to support the definition of the integrity requirement for the data process. 

These assurance levels are defined to be compatible with other safety analyses conducted for aircraft applications. 

| Data Process      |
|-------------------|
| Assurance Level   |
| on State-Provided |
| Data              |
| (leAO)            |
| 1                 |
| Critical          |

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

2 
Essential 
3 
Routine 

Data Process Assurance Levels applicable to Aeronautical Information are set out in RTCA DO-201AlEUROCAE ED-77. Assurance Levels for applications of data not covered by RTCA DO-201AlEUROCAE ED-77 will need to be determined by the end-user or application provider. 

For applications integrated into aircraft, the required assurance level for the aeronautical data process is identified, based on the overall system architecture through allocation of risk determined using a preliminary system safetyÂ· 
assessment. Guidance on this assessment can be found in: 
SAE ARP4761 Guidelines and Methods/or Conducting the Safety Assessment Process on Civil Airborne Systems and Equipment; 

SAE ARP4754IEUROCAE ED-79} Certification Considerations/or 
Highly Integrated or Complex Aircraft Systems; 
JAA AMJ 25.1309 Advisory Material Joint, System Design and Analysis; 
FAA AC 25.1309-1AAdvisory Circular, System Design and 
Analysis; 
RTCA DO-178B/ EUROCAE ED-12B} Software Considerations in 
Airborne Systems and Equipment Certification; 
RTCA DO-201A1EUROCAE ED-77} Industry Requirements/or 
Aeronautical Information. 
The failure condition categories listed below are applicable to aircraft applications, having been derived from this guidance material. The aircraft failure condition categories are: 

B 
Catastrophic 
prevent continued safe flight and 
landing. 
Hazardous/ 
Failure conditions that would reduce 
Severe-
Major 
the capability of 
the aircraft or the 
ability of 
the crew to cope with 
adverse operating conditions to the 
extent that there would be: 
(1) a large reduction in safety 
margins or functional capabilities, 
(2) physical distress or higher 
workload such that the flight crew 
could not be relied on to perfonn 
their tasks accurately or completely, 
or 
(3) adverse effects on occupants 
including serious or potentially fatal 
injuries to a small number of 
those 
occupants. 
Major 
Failure conditions that would reduce 
the capability of 
the aircraft or the 
ability of 
the crew to cope with 
adverse operating conditions to the 
C 
extent that there would be, for 
example, a significant reduction in 
safety margins or functional 
capabilities, a significant increase in 
crew workload or in conditions 
impairing crew efficiency, or 
discomfort to occupants, possibly 
including injuries. 
Minor 
Failure conditions that would not 
significantly reduce aircraft safety, 
and that would involve crew actions 
that are well within their capabilities. 
D 
Minor failure conditions may include, 
for example, a slight reduction in 
safety margins or functional 
capabilities, a slight increase in crew 
workload, such as routine flight plan 
changes, or some inconvenience to 
occupants. 
No Safety 
Failure conditions that do not affect 
Effect 
the operational capability of 
the 
E 
aircraft or increase crew workload. 

In addition to assessing the failure condition category associated with malfunctions caused by data, it is important to detennine the required assurance level associated with loss of a function due to data. This is generally defmed by the availability requirement for an aircraft level function. 

For example, the availability of a precision approach capability may be defined as a major failure condition implying an equipment design assurance Level C. The data process should be consistent with the tightest assurance level requirements, either derived from the malfunction effect or availability requirement, in the approach example this would equate to a data process assurance level 2. 

## B.1.4 Traceability

User requirements for traceability are typically stated in terms of the duration of time that specific data elements must be traceable. It is recommended that data be retained as long as the data is in use. 

## B.1.5 Timeliness

Many data elements have an identified period for which the data is valid. The period of validity may be based upon an update period from the supplier or the underlying characteristics of the data itself. An example of an update period is when States publish aeronautical data on a 28 day AIRAC cycle. An example of the period being based on its characteristics is terrain data supporting a terrain application: the period of time for which terrain data remains acceptable should be determined during evaluation of the system. 

The requirement is to use valid, current data. This responsibility rests with the end-user. The end-user may choose to discharge this responsibility by purchasing a particular set of data, based upon its declared effective period. 

## B.1.6 Completeness

Completeness includes defining any requirements that define the mlnImum acceptable set of data to perform the intended function. One minimum set may be defined at time of equipment approval, while a larger set may be identified by the end-user. 

The requirement defined at time of equipment approval is typically just that there is a database that is consistent with planned operations. The requirement defined for the operation is for the database to contain a particular set of data for the area(s) where operations are intended. 

For many systems, database size limitations restrict the total amount of data that can be stored. In this case, selection criteria can be used to reduce the total content. This selection criteria must be consistent with the operational requirements of the end-user. For example, 

1) a navigation database may contain all approaches within the U.S., excluding 
all approaches to runways less than 5,000 feet long; or, 
2) a terrain database may contain terrain for a complete area with higher 
resolution for all airports with runways longer than 3,500 ft. 
The responsibility to have the necessary data for the areas of intended operation is placed on the end-user. The end-user may choose to discharge this responsibility by purchasing a particular set of data, based upon its declared coverage region. 

## B.1. 7 Format

This definition of the fonnat of delivered data must be adequate to ensure that the data, when loaded into the end application, is interpreted in a manner that is consistent with the intent of the data. The fonnat of the data will also define the transmission resolution of data. 

## Data Element Format B.1.7.1

There are two potential levels of fonnatting: basic data fonnat and compression techniques. Examples of the basic data fonnat include: 

1) definition of 
the parameter; 
2) sign convention; 
3) units; or, 
4) coding method (e.g., binary-coded decimal, two's complement) 
For delivery into the application, a data compression technique may be used to reduce the required amount of memory. In this case, the compression technique is part of the defined fonnat. The decompressed data must be the same as the data before compression. 

Generally this assurance can be provided through tool qualification. 

## Relationship Between Data Elements B.1.7.2

Definition of relationships between data elements IS crucial to the proper application of the data for its intended function. 

Data relationships can exist between: 

- 
data characters within a data element 
- 
data elements within a data record 
- 
data records within the same data file 
- 
data records and other data files 
For RNA 
V applications, examples of each are: 

- 
The elevation field in airports and runways file must have both a numeric 
value and a sign indication for above and below sea level; 
- 
The navaid class field indicates whether there is a VOR and/or DME, and thus 
those fields must be present; 
- 
When defining a procedure the relationship between the fixes constitute the 
procedure. While fixes can be defined as latitudes and longitudes, they only 
have real meaning when linked into a procedure; 
- 
The use of a waypoint by an airway, procedure, company route or preferred 
route must be supported in the appropriate data file. 
Information related to defining relationships between data elements can be found in RTCA DO-201AlEUROCAE ED-77 and ARlNC Specification 424. Based on the specifics of the application, the relationships defined in these documents may or may not be adequate. For procedures that were originally designed for RNA 
V 
equipment, RTCA DO-201AlEUROCAE ED-77 and ARINC 424 should be adequate. In the case of inadequate definition in these documents of data element relationships for the application's intended function, specific supplemental definition should be provided. 

One method of ensuring the format is sufficiently defined, and is compatible, is to test database updates in a simulated environment. This method is particularly useful when coding procedures that were not originally designed to be RNA 
V 
procedures. 

This type of validation is a very effective means of ensuring the database path and published procedures are compatible. Other methods may be used, including adequate definition of the data format. 

## B.2 Data Supplier Requirements B.2.1 Accuracy

Each data supplier must consider the accuracy provided by its suppliers, any potential changes to the accuracy introduced by the data process, and the accuracy required by the user. If the resolution of data is small relative to the accuracy requirement, and if any data translations are performed with a small processing error, it is sufficient for each data supplier in a chain to simply pass the accuracy requirement to the predecessor without modification. 

## B.2.2 Resolution

Within the process of a data supplier, the resolution should be considered with respect to the accuracy requirement as described in Section B.2.1. 

## B.2.3 Assurance Level

The user requirement for integrity is passed along an Aeronautical Data Chain. It is recommended that the integrity requirement be defined in the context of an assurance level (1, 2, or 3). The application of these levels is discussed in Section C.2.3. 

## B.2.4 Traceability

The user requirement for traceability is passed along an Aeronautical Data Chain. 

## B.2.S Timeliness

The user requirement for timeliness is passed along an Aeronautical Data Chain. 

## B.2.6 Completeness

It is important that the selection criteria are co-ordinated and agreed upon with the user. Since the end-user frequently cannot readily assess the storage requirements associated with a particular set of selection criteria, the data supplier may be the one who develops this criteria in order to meet system capacity constraints. 

## B.2.7 Format

The definition of the format includes the format for individual data elements and the relationship between data elements (see Section B.1.7). 

## Appendixc Consideration And Guidance On Compliance With Data Processing Requirements

This appendix establishes an acceptable means, but not the only means, of complying with the requirements of Section 2.4, "Aeronautical Data Processing Requirements". 

The primary objective of the data process is to supply data that meets the data quality requirements. The requirements of Sections 2.3 and 2.4 have been developed to support this objective. This appendix is organised to focus on the relationship between the procedures, the process requirements, and the identified data quality requirements. The guidance in this appendix is organised based upon the following data quality characteristics. 

Note: This appendix is illustrative and does not create requirements on software developers or data processors additional to those specified in Section 2. 

## C.I Accuracy

An analysis of the data process specified in the procedures should be accomplished (see Section 2.4.1, item 8). For data originated locally, the analysis should include the accuracy and resolution of the process that originated and validated the data. For data not originated locally, the analysis must consider the accuracy and resolution delivered from the preceding data supplier. Moving and storing data does not affect accuracy, but the effects of every format/translation must be evaluated. 

## C.2 Assurance Level

The integrity requirement will generally be stated as a data process Assurance Level (see Appendix B). 

This section describes verification and validation techniques, and explains how they relate to the assurance levels. Validation and verification may be applied to all the data or a statistically significant sample of the data. For a data quality requirement of Level 3, validation and verification are recommended but not required. 

## C.2.1 Validation

Validation is the activity where a data element is checked as having a value that is fully applicable to the identity ascribed to the data element, or a set of data elements is checked as being acceptable for their purpose. 

The following paragraphs describe the basic methods of validation. Any or all of these methods may be used as part of a data process. 

## C.2.1.1 Validation By Application

One method of validation is to apply data under test conditions. In certain cases this may not be practical. Validation by application is considered to be the most effective form of validation. For example, flight inspection of final approach segment data prior to publication can be used to ensure that the published data is acceptable. 

## Logical Consistency C.2.1.2

Logical consistency validates by comparing the relationship between two different data sets (Figure C-l). For example, published headings can be compared to the computed heading between two fixes, or contour lines of adjacent cells can be compared. 

This method cannot completely validate the data as there is the possibility that the different data sets include the same error. Independence of the data sets substantially improves the effectiveness of this type of validation. 

Examples of logical consistency include: 

1) comparison of 
duplicate information; or, 
2) contextual relationships between data elements (related record, field and 
character checks, colinearity checks). 

## Semantic Consistency C.2.1.3

Semantic consistency validates by comparing data to an expected value or range of values for the data characteristics (Figure C-2). 

This method cannot completely validate the data as there is the possibility that the data has an error that lies within the expected range. 

Examples of semantic consistency include: 

- 
presence versus absence of 
data 
- 
field and character context 
- 
range limit checks 
- 
geographic vicinity checks 
- 
use in the declared time period of 
validity 
- 
field sizes 

## C.2.2 Verification Techniques

Verification is a process for checking the integrity of a data element whereby the data element is compared to another source, either from a different process or from a different point in the same process. While verification cannot ensure that the data is correct, it can be effective at ensuring that the data has not been corrupted by the data process. 

## C.2.2.T Digital Error Detection Techniques

Digital error detection techniques can be used to detect errors during the transfer or storage of data. Examples of these techniques include cyclic redundancy checks CCRCs), parity, Hamming codes, and Reed-Solomon codes. Coding techniques can be effective regardless of the transmission media, such as computer disks, modem communication, or the Internet. 

While the data quality integrity requirement is specified as an assurance level, digital error detection techniques are unique in the data process in that they can be numerically evaluated. In fact, the only way to assess the performance of a particular technique is to assess its numerical performance. Therefore, Table C-I 
may be used to associate the data quality assurance levels to a probability of undetected corruption. These probabilities can only be applied to digital error detection techniques. They may not be applied to any other portion of the data process. 

| Assurance Level    | Probability    | of          |
|--------------------|----------------|-------------|
| undetected         | corruption     |             |
| 1                  |                |             |
| S;1Q-8             |                |             |
| 2                  |                |             |
| S;10-              |                |             |
| 5                  |                |             |
| 3                  | Not            | applicable. |

Data Process Assurance Levels applicable to Aeronautical Information are set out in RTCA DO-201AJEUROCAE ED-?? 

The underlying probability of an error occurring and the amount of the protected data should be considered when demonstrating compliance to this requirement. 

The most common form of error detection for navigation data is the application of a CRC. A CRC is a coding algorithm whereby a sequence of N data bits is manipulated by an algorithm to produce a block of n bits, known as the CRC, where n is less than N. A check of the integrity of the data can be performed by comparing the result of the application of the algorithm with the declared expected result. By careful choice of the algorithms employed, in conjunction with the relative values of n and N, a CRC will detect a specified proportion of the potential erroneous bit patterns. 

Properly selected algorithms are capable of providing a probability of undetected corruption by random errors of less than 2"", where n is the length of the polynomial. 

## C.2.2.2 Feedback

Feedback testing is the comparison of a data set between its output and input state 
(Figure C-3). A common method of feedback is manual confirmation, whereby data is copied to a new location and confirmed to be correct. 

## C.2.2.3 Independent Redundancy

Independent redundancy testing involves processing the same data through two 
(or more) independent processors and comparing the data output of each process 
(Figure C-4). 

## C.2.2.4 Update Comparison

Updated data can be compared to its previous version.. This comparison can identify all data elements that have changed. The list of changed elements can then be compared to a similar list generated by the supplier. A problem can be detected if an element is identified as changed on one list and not the other. This method can also be used to reduce the amount of data that is subjected to other forms of verification, focusing in on only those elements that have changed. 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---

## C.2.3 Application Of Validation And Verification

Validation and verification are both employed by a data process to ensure that data meets the associated data quality requirement for integrity. 

## Assurance Levell C.2.3.1

Due to the critical nature of undetected errors for a process designated Levell, it is important that there is no opportunity for errors to be introduced by human error in the data process. 

In addition, tools that can modify the data in an undetected manner must be qualified to a level consistent with the hazardous or catastrophic failure condition. In order to determine the level of qualification, the architecture of the data process must be examined. 

Below are examples of process architectures supporting hazardous/catastrophic failure conditions (Levell Process). These examples can be linked to form an Aeronautical Data Chain of any length. When evaluating a Level 1 process which relies on a CRC or other coding technique, it is important to ensure that the intermediate process between the application and removal of the CRC does not contain any design errors which could generate a CRC value for invalid data. The ability of a CRC to detect errors can only be quantified for random errors. Note that the shaded boxes indicate applications or tools qualified consistent with the hazardous or catastrophic failure condition. 

The most basic Level 1 process is shown in Figure C-5 below. 

Assurance is provided by the originally generated eRe value and the verification of the eRe value in the end application. Both are qualified in accordance with the hazardous or catastrophic failure condition. 

Of significant interest is any tool which has the ability to generate the same CRC 
as was originally applied. In Figure C-6, the tool can generate that CRC value and therefore should be qualified to a level consistent with the failure condition 
(hazardous or catastrophic). 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
Tools that translate or format the data do not need to be qualified as long as the subsequent participant can recover the original format. This enables the subsequent participant to verify the eRe value and ensure that there are no undetected errors introduced by the unqualified tool. 

Since verification of the eRe value is only effective against random errors, it is important that the unqualified tool cannot generate a eRe value which would pass the subsequent verification. 

To support traceability and immediate detection of transmission errors, the tools may generate and verify other eRe values. In this case, the tool may have to be qualified to a lower level of assurance, depending on the data quality requirements. 

In Figure C-7, the intermediate tools do not have the ability to generate a CRC 
value which would pass the subsequent verification. Therefore, these tools do not have to be qualified to a level consistent with the hazardous or catastrophic failure condition. 

The tools can assemble, format, distribute and receive without exposing the data to undetected errors at the end application. It is recommended that a different CRC value be generated for data before distribution and after receiving. The use of such a CRC will prevent the situation where an error is not detected until the end of an Aeronautical Data Chain. While such a detected error results in a safe situation, it is undesirable and would have to be traced back up the chain until the source of the error were discovered. The tools should be qualified to a lower level, based on how they support other data quality requirements (e.g., traceability, completeness, format). 

Assurance is provided by the originally generated eRe value, use of a qualified tool, and the verification of the eRe value in the end application. All three are qualified in accordance with the hazardous or catastrophic failure condition. For example, the tool may be qualified using the standards ofDO-178BIEDI2B, Section 12.2 for Level A or B applications. 

Finally, Figure C-8 illustrates how the original CRC value can be verified using a verification qualified tool, since the tool itself cannot introduce errors in the data. 

The verification tool should be qualified to a lower level, based on how they support other data quality requirements (e.g., traceability, completeness, format). 

--`,``,````,`,`,``,``,````,`````-`-`,,`,,`,`,,`---
~----------------------------------------------------------------~ 
The verification tool can be qualified to a lower standard since the tool does not have the ability to introduce errors. 

## Fieure C-8 Process With Qualified Verification Tool Assurance Level 2 C.2.3.2

For Assurance Level 2, validation by application is not required. 

However, application remains the most effective means of validation and can be used. 

Logical and semantic consistency may also be used as components of the overall validation. 

As with Level 1 data, validation is typically accomplished by the originator of the data. Once the data is validated, verification techniques must be used to ensure that the technical content of the data is not modified at any stage of the process. 

Anyone or a combination of the validation methods identified in Section C.2.1 
may be applied. 

Table C-2 provides additional information on how the verification methods may be applied and states what issues must be addressed. 

## C.2.3.3 Assurance Level 3

For a data assurance Level 3, validation and verification are recommended but not required. 

Update 
- 
- 
- 
Comparison 
Requires a list 
of 
modified 
elements from 
all sources. 
Skills 
competency of 
individuals 
performing 
manual 
comparison 
Tool 
qualification of 
any tools used 
to accomplish the comparison 
Verification 
Digital Error 
Feedback 
Independent 
Technique 
Detection 
Redundancy 
Issues that - Tool 
- Skills 
- Independence 
Must be 
qualification 
competency of 
of 
the two (or 
Addressed 
of 
any tools 
individuals 
more) 
used to 
performing 
processes 
accomplish 
manual 
- Skills 
the digital 
feedback 
competency of 
error detection - Tool 
individuals 
qualification of 
performing 
any tools used 
manual 
to accomplish 
comparison 
the feedback 
- Tool 
companson 
qualification of 
any tools used 
to accomplish the comparison 

Table C-3 provides additional information on how the verification methods may be applied to the six phases of process defined in sections 1.6.5.2 through 1.6.5.3. 

The first row includes phases that involve moving data from one physical location or medium to another. Examples are copying files to a removable disk and facsimile of written data. Assembling of data is the process whereby it is moved from different locations to a common location. 

The second row includes phases that involve transforming data from one data structure to another. Examples include transforming data from written form to binary form. 

Verification 
Digital Error 
Feedback 
Independent 
Update 
Technique 
Detection 
Redundancy 
Comparison 
Applications 
Effective, 
Feedback is an 
Independent 
Update 
to: 
assurance can 
effective means of redundancy is an 
comparison is an 
Receive Phase 
be 
verifying data 
effective means of effective means of 
Assemble 
numerically 
after 
verifying data 
verifying data 
Phase 
demonstrated. 
moving/storing. 
during 
during 
Select Phase 
Manual feedback 
moving/storing. 
moving/storing. 
Distribute 
can be used as 
Phase 
part of 
a Level C 
process. 
Application to: 
Not 
Feedback can be 
Independent 
Update 
Translate 
applicable. 
used when 
redundancy is an 
comparIson IS an 
Phase 
transforming data. 
effective means of not an effective 
Format Phase 
In order to 
verifying manual 
means of 
compare the 
transformations. 
verifying 
output of 
the 
For automated 
transformation, as 
transformation to 
transformations, 
the transformation 
the input, it is 
the tool that 
could introduce 
necessary to 
performs the 
the same error in 
transform one or 
transformation 
both updates. 
both to a common 
should be 
However, use of 
form (e.g., 
qualified. 
update 
| ASCII).             | comparIson can     |
|---------------------|--------------------|
| Therefore,          | provide some       |
| feedback provides   |                    |
| assurance           |                    |
| verification only   |                    |
| if                  | provided the prior |
| the means           |                    |
| of                  | update has been    |
| transformation for  | validated (by      |
| the verification is |                    |
| application).       |                    |
| independent         |                    |
| of                  | the                |
| means               |                    |
| of                  |                    |
| transformation      |                    |
| that is being       |                    |
| verified.           |                    |

## C.3 Traceability

| Configuration management    |
|-----------------------------|
| requirements.               |

## C.4 Timeliness

The data process achieves timeliness through data configuration management. 

Timeliness can be assured by including any limits on the effective period with the data elements. These limits may be associated with individual data elements or data sets. If the effective period is defined for a data set, it should account for the effective dates of all of the individual data elements. 

## C.S Completeness

It is important that no data is inadvertently discarded. The skills competency of individuals who select and assemble data must be assured. Tools that assemble or select data must be qualified for this purpose. 

## C.6 Format

The procedures should ensure that the output data will comply with the specified format. Compliance is typically accomplished by qualification of the tool that generates the delivered product. 

## C.7 Error Reporting

The procedures should define how detected errors are reported. As identified in Section 2 of this standard, errors should be traced back to the source. If data that contains an error is delivered, it is very important that the user is also notified of the error. The action taken in event of a detected error should be based upon the type of error: some errors may be very significant, requiring immediate notification. The procedures should identifY how an error is categorised, and based on that categorisation what action is taken. Three significant issues that must be addressed in each case are: 

- 
To whom are the errors reported? 
- 
How quickly are errors reported? 
- 
Does the process exclude the data containing the error, is it delivered with the 
error, or is an attempt made to correct the error? 
In addition, the process should record all error reports. 

It is beneficial to periodically review the error reports to identifY trends in data errors that may be correctable. The error report should identifY any notification of error from a user, any errors determined during validation or verification, and any errors reported to a prior data supplier. 

--`,``,````,`,`,``,``,````,`````-`-`,,`